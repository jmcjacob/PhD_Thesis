\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{agsm}
\providecommand \oddpage@label [2]{}
\citation{sener2017active}
\citation{sirinukunwattana2016locality}
\citation{deng2009imagenet}
\citation{veeling2018rotation}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{v}{chapter*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{List of Tables}{vii}{chapter*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{List of Terms}{viii}{chapter*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{List of Abbreviations}{ix}{chapter*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{List of Symbols}{x}{chapter*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Acknowledgements}{xi}{chapter*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Declaration}{xii}{chapter*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Abstract}{xiii}{chapter*.10}\protected@file@percent }
\citation{geert2017survey}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{ch:introduction}{{1}{1}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Introduction to Problem}{1}{section.1.1}\protected@file@percent }
\newlabel{sec:intoduction_to_problem}{{1.1}{1}{Introduction to Problem}{section.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Research Contributions}{1}{section.1.2}\protected@file@percent }
\newlabel{sec:research_contributions}{{1.2}{1}{Research Contributions}{section.1.2}{}}
\citation{tizhoosh2018artificial}
\citation{settles2012active}
\citation{carse2019active}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Thesis Structure}{2}{section.1.3}\protected@file@percent }
\newlabel{sec:thesis_structure}{{1.3}{2}{Thesis Structure}{section.1.3}{}}
\citation{maron2019systematic}
\citation{guo2017calibration}
\citation{carse2021robust}
\citation{carse2022calibration}
\citation{carse2019active}
\citation{settles2012active}
\citation{gal2017deep}
\citation{pop2018deep}
\citation{sener2017active,zhdanov2019diverse,kirsch2019batchbald}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Annotator Efficient Active Learning}{5}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{ch:active_learning}{{2}{5}{Annotator Efficient Active Learning}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Introduction}{5}{section.2.1}\protected@file@percent }
\newlabel{sec:active_introduction}{{2.1}{5}{Introduction}{section.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Active Learning for Medical Image Analysis}{5}{subsection.2.1.1}\protected@file@percent }
\newlabel{subsec:active_for_medical_image_analysis}{{2.1.1}{5}{Active Learning for Medical Image Analysis}{subsection.2.1.1}{}}
\citation{sirinukunwattana2016locality}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Pool-based active learning framework.\relax }}{6}{figure.caption.16}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:pool_based_active_learning}{{2.1}{6}{Pool-based active learning framework.\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Deep Active Learning for Digital Pathology}{6}{subsection.2.1.2}\protected@file@percent }
\newlabel{subsec:active_deep_learning}{{2.1.2}{6}{Deep Active Learning for Digital Pathology}{subsection.2.1.2}{}}
\citation{settles2012active}
\citation{lewis1995sequential}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Active Learning for Medical Images Review}{7}{section.2.2}\protected@file@percent }
\newlabel{sec:active_review}{{2.2}{7}{Active Learning for Medical Images Review}{section.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Pool-Based Active Learning Query Strategies}{7}{subsection.2.2.1}\protected@file@percent }
\newlabel{subsec:active_pool_based}{{2.2.1}{7}{Pool-Based Active Learning Query Strategies}{subsection.2.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Traditional Machine Learning Query Strategies}{7}{section*.17}\protected@file@percent }
\citation{seung1992query}
\citation{settles2007multiple}
\citation{roy2001toward}
\citation{cohn1996active}
\citation{settles2008analysis}
\citation{ren2021survey}
\@writefile{toc}{\contentsline {subsubsection}{Deep Learning Query Strategies}{8}{section*.18}\protected@file@percent }
\citation{wang2017cost}
\citation{lee2013pseudo}
\citation{demir2015novel}
\citation{chen2014cross}
\citation{gal2016dropout}
\citation{gal2017deep}
\citation{shin1949mathematical}
\citation{freeman1965elementary}
\citation{kampffmeyer2016semantic}
\citation{houlsby2011bayesian}
\citation{gutman2016skin}
\@writefile{toc}{\contentsline {subsubsection}{Scoring Query Strategies}{9}{section*.19}\protected@file@percent }
\newlabel{eq:bayesian_cnn}{{2.1}{9}{Scoring Query Strategies}{equation.2.2.1}{}}
\citation{ducoffe2018adversarial}
\citation{settles2012active}
\citation{kurakin2016adversarial}
\citation{sener2017active}
\citation{farahani2009facility}
\citation{sener2017active}
\citation{sener2017active}
\citation{rasmus2015semi}
\citation{krizhevsky2009learning}
\@writefile{toc}{\contentsline {subsubsection}{Batch Aware Query Strategies}{10}{section*.20}\protected@file@percent }
\citation{kirsch2019batchbald}
\citation{gal2017deep}
\citation{lecun1998gradient}
\citation{cohen2017emnist}
\citation{darlow2018cinic}
\citation{zhdanov2019diverse}
\citation{lecun1998gradient}
\citation{krizhevsky2009learning}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces A visual illustration of the core-sets query strategy, in which four points are selected that cover all other data points and minimize $\delta _s$\nobreakspace  {}\citep  {sener2017active}.\relax }}{11}{figure.caption.21}\protected@file@percent }
\newlabel{fig:core-set}{{2.2}{11}{A visual illustration of the core-sets query strategy, in which four points are selected that cover all other data points and minimize $\delta _s$~\citep {sener2017active}.\relax }{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Application of Active Learning for Medicine}{12}{subsection.2.2.2}\protected@file@percent }
\newlabel{subsec:active_applications}{{2.2.2}{12}{Application of Active Learning for Medicine}{subsection.2.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Active Learning for Annotation Efficiently}{12}{subsection.2.2.3}\protected@file@percent }
\newlabel{subsec:active_annotation_efficiently}{{2.2.3}{12}{Active Learning for Annotation Efficiently}{subsection.2.2.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Annotator Efficient Active Learning for Histopathology}{12}{section.2.3}\protected@file@percent }
\newlabel{sec:active_annotator_efficient}{{2.3}{12}{Annotator Efficient Active Learning for Histopathology}{section.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Problem Setting defined by Review}{12}{subsection.2.3.1}\protected@file@percent }
\newlabel{subsec:active_problem_settings}{{2.3.1}{12}{Problem Setting defined by Review}{subsection.2.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Region-Based Active Learning}{12}{subsection.2.3.2}\protected@file@percent }
\newlabel{subsec:active_region_based}{{2.3.2}{12}{Region-Based Active Learning}{subsection.2.3.2}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Region-based active learning\relax }}{13}{algocf.1}\protected@file@percent }
\newlabel{alg:regionbased}{{1}{13}{Region-Based Active Learning}{algocf.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Active Learning Experiments}{13}{section.2.4}\protected@file@percent }
\newlabel{sec:active_experiments}{{2.4}{13}{Active Learning Experiments}{section.2.4}{}}
\citation{sirinukunwattana2016locality}
\citation{shao2018deep}
\citation{sirinukunwattana2016locality}
\citation{sirinukunwattana2016locality}
\citation{sirinukunwattana2016locality}
\citation{srivastava2014dropout}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Three example regions from the CRCHistoPhenotypes dataset\nobreakspace  {}\cite  {sirinukunwattana2016locality} are shown, each containing multiple nuclei that will be extracted into patches and augmented.\relax }}{14}{figure.caption.23}\protected@file@percent }
\newlabel{fig:region_example}{{2.3}{14}{Three example regions from the CRCHistoPhenotypes dataset~\cite {sirinukunwattana2016locality} are shown, each containing multiple nuclei that will be extracted into patches and augmented.\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Dataset}{14}{subsection.2.4.1}\protected@file@percent }
\newlabel{subsec:active_dataset}{{2.4.1}{14}{Dataset}{subsection.2.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Training Parameters}{14}{subsection.2.4.2}\protected@file@percent }
\newlabel{subsec:active_training}{{2.4.2}{14}{Training Parameters}{subsection.2.4.2}{}}
\citation{zeiler2012adadelta}
\citation{prechelt1998early}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces The Convolutional Neural Network architecture employed for nuclei classification in the region-based active learning experiments.\relax }}{15}{table.caption.24}\protected@file@percent }
\newlabel{tab:active_learning_cnn}{{2.1}{15}{The Convolutional Neural Network architecture employed for nuclei classification in the region-based active learning experiments.\relax }{table.caption.24}{}}
\newlabel{eq:generalization_loss}{{2.2}{15}{Training Parameters}{equation.2.4.2}{}}
\citation{sener2017active}
\citation{gal2017deep}
\citation{glorot2010understanding}
\newlabel{eq:training_progression}{{2.3}{16}{Training Parameters}{equation.2.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Experiment Setup}{16}{subsection.2.4.3}\protected@file@percent }
\newlabel{subsec:active_experiments}{{2.4.3}{16}{Experiment Setup}{subsection.2.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.4}Results}{16}{subsection.2.4.4}\protected@file@percent }
\newlabel{subsec:active_results}{{2.4.4}{16}{Results}{subsection.2.4.4}{}}
\citation{ren2021survey}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Test results for each query strategy after 50 active iterations.\relax }}{17}{table.caption.25}\protected@file@percent }
\newlabel{tab:query_results}{{2.2}{17}{Test results for each query strategy after 50 active iterations.\relax }{table.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Average test accuracy of trained models using different amounts of annotated regions selected through various query strategies.\relax }}{17}{figure.caption.26}\protected@file@percent }
\newlabel{fig:active_learning_accuracy}{{2.4}{17}{Average test accuracy of trained models using different amounts of annotated regions selected through various query strategies.\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Average test mean class accuracy of trained models using different amounts of annotated regions selected through various query strategies.\relax }}{18}{figure.caption.27}\protected@file@percent }
\newlabel{fig:active_learning_mean_class_accuracy}{{2.5}{18}{Average test mean class accuracy of trained models using different amounts of annotated regions selected through various query strategies.\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Average test loss of trained models using different amounts of annotated regions selected through various query strategies.\relax }}{18}{figure.caption.28}\protected@file@percent }
\newlabel{fig:active_learning_loss}{{2.6}{18}{Average test loss of trained models using different amounts of annotated regions selected through various query strategies.\relax }{figure.caption.28}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Conclusion}{19}{section.2.5}\protected@file@percent }
\newlabel{sec:active_conclusion}{{2.5}{19}{Conclusion}{section.2.5}{}}
\citation{carse2021unsupervised}
\citation{litjens2017survey}
\citation{madabhushi2016image}
\citation{bengio2013representation}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Unsupervised Representation Learning}{20}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{ch:unsupervised_representation_learning}{{3}{20}{Unsupervised Representation Learning}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Introduction}{20}{section.3.1}\protected@file@percent }
\newlabel{sec:unsupervised_intro}{{3.1}{20}{Introduction}{section.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Unsupervised Representation Learning for Images}{20}{subsection.3.1.1}\protected@file@percent }
\newlabel{subsec:unsupervised_for_medical}{{3.1.1}{20}{Unsupervised Representation Learning for Images}{subsection.3.1.1}{}}
\citation{deng2009imagenet}
\citation{veeling2018rotation}
\citation{deng2009imagenet}
\citation{veeling2018rotation}
\citation{weiss2016survey}
\citation{oord2018representation}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces (a) An example image from the ImageNet dataset\nobreakspace  {}\cite  {deng2009imagenet}. (b) Extracted overlapping patches with those used to produce context and autoregressor direction highlighted. (c) An example image from the Patch Camelyon dataset\nobreakspace  {}\cite  {veeling2018rotation}. (d) Extracted overlapping patches with those used to produce context and autoregressor direction highlighted.\relax }}{21}{figure.caption.29}\protected@file@percent }
\newlabel{fig:example_cpc_patches}{{3.1}{21}{(a) An example image from the ImageNet dataset~\cite {deng2009imagenet}. (b) Extracted overlapping patches with those used to produce context and autoregressor direction highlighted. (c) An example image from the Patch Camelyon dataset~\cite {veeling2018rotation}. (d) Extracted overlapping patches with those used to produce context and autoregressor direction highlighted.\relax }{figure.caption.29}{}}
\citation{henaff2019data}
\citation{oord2016pixel}
\citation{veeling2018rotation}
\citation{litjens20181399}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Summary of Work}{22}{subsection.3.1.2}\protected@file@percent }
\newlabel{subsec:unsupervised_summary}{{3.1.2}{22}{Summary of Work}{subsection.3.1.2}{}}
\citation{henaff2019data,oord2018representation}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Proposed active learning framework with learnt representations from unsupervised representation learning on unannotated data.\relax }}{23}{figure.caption.30}\protected@file@percent }
\newlabel{fig:active_unsupervised_learning_framework}{{3.2}{23}{Proposed active learning framework with learnt representations from unsupervised representation learning on unannotated data.\relax }{figure.caption.30}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Review of Deep Unsupervised Representation Learning}{23}{section.3.2}\protected@file@percent }
\newlabel{sec:unsupervised_review}{{3.2}{23}{Review of Deep Unsupervised Representation Learning}{section.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Unsupervised Representation Learning}{23}{subsection.3.2.1}\protected@file@percent }
\newlabel{subsec:unsupervised_representation}{{3.2.1}{23}{Unsupervised Representation Learning}{subsection.3.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Deep Unsupervised Representation Learning}{23}{subsection.3.2.2}\protected@file@percent }
\newlabel{subsec:unsupervised_deep_representation}{{3.2.2}{23}{Deep Unsupervised Representation Learning}{subsection.3.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Unsupervised Representation Learning for Medical Images}{23}{subsection.3.2.3}\protected@file@percent }
\newlabel{subsec:unsupervise_representation_for_medical}{{3.2.3}{23}{Unsupervised Representation Learning for Medical Images}{subsection.3.2.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Multi-Directional Contrastive Predictive Coding}{23}{section.3.3}\protected@file@percent }
\newlabel{sec:unsupervised_multi_directional_cpc}{{3.3}{23}{Multi-Directional Contrastive Predictive Coding}{section.3.3}{}}
\citation{gutmann2010noise}
\citation{oord2018representation}
\citation{deng2009imagenet}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Contrastive Predictive Coding}{24}{subsection.3.3.1}\protected@file@percent }
\newlabel{subsec:unsupervised_cpc}{{3.3.1}{24}{Contrastive Predictive Coding}{subsection.3.3.1}{}}
\newlabel{eq:density_ratio}{{3.1}{24}{Contrastive Predictive Coding}{equation.3.3.1}{}}
\newlabel{eq:InfoNCE}{{3.2}{24}{Contrastive Predictive Coding}{equation.3.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Contrastive Predictive Coding for Computer Vision}{24}{subsection.3.3.2}\protected@file@percent }
\newlabel{subsec:unsupervised_cpc_for_vision}{{3.3.2}{24}{Contrastive Predictive Coding for Computer Vision}{subsection.3.3.2}{}}
\citation{oord2016pixel}
\citation{oord2016pixel}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Multi-Directional Contrastive Predictive Coding}{25}{subsection.3.3.3}\protected@file@percent }
\newlabel{subsec:unsupervised_mdcpc}{{3.3.3}{25}{Multi-Directional Contrastive Predictive Coding}{subsection.3.3.3}{}}
\citation{veeling2018rotation}
\citation{veeling2018rotation}
\citation{litjens20181399}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Architecture of a Multi-Directional Masked Block\relax }}{26}{figure.caption.31}\protected@file@percent }
\newlabel{fig:multi-directional_masked_block}{{3.3}{26}{Architecture of a Multi-Directional Masked Block\relax }{figure.caption.31}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Unsupervised Representation Learning Experiments}{26}{section.3.4}\protected@file@percent }
\newlabel{sec:unsupervised_experiments}{{3.4}{26}{Unsupervised Representation Learning Experiments}{section.3.4}{}}
\citation{xie2017aggregated}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Dataset}{27}{subsection.3.4.1}\protected@file@percent }
\newlabel{subsec:unsupervised_dataset}{{3.4.1}{27}{Dataset}{subsection.3.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Experiment Setup}{27}{subsection.3.4.2}\protected@file@percent }
\newlabel{subsec:unsupervised_experiment}{{3.4.2}{27}{Experiment Setup}{subsection.3.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Training Parameters}{27}{subsection.3.4.3}\protected@file@percent }
\newlabel{subsec:unsupervised_training}{{3.4.3}{27}{Training Parameters}{subsection.3.4.3}{}}
\citation{kingma2014adam}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Results}{28}{subsection.3.4.4}\protected@file@percent }
\newlabel{subsec:unsupervised_results}{{3.4.4}{28}{Results}{subsection.3.4.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Mean test accuracies of the CNN classifiers with different pre-training (standard deviations in parentheses).\relax }}{29}{table.caption.32}\protected@file@percent }
\newlabel{tab:cnn_results}{{3.1}{29}{Mean test accuracies of the CNN classifiers with different pre-training (standard deviations in parentheses).\relax }{table.caption.32}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Conclusion}{29}{section.3.5}\protected@file@percent }
\newlabel{sec:conclusion}{{3.5}{29}{Conclusion}{section.3.5}{}}
\citation{carse2021robust}
\citation{codella2018skin,Combalia2019,Tschandl2018}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Asymmetrical Selective Classification}{30}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{ch:selective_classification}{{4}{30}{Asymmetrical Selective Classification}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Introduction}{30}{section.4.1}\protected@file@percent }
\newlabel{sec:selective_introduction}{{4.1}{30}{Introduction}{section.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Problem Statement}{30}{subsection.4.1.1}\protected@file@percent }
\newlabel{subsec:selective_probelm_statement}{{4.1.1}{30}{Problem Statement}{subsection.4.1.1}{}}
\citation{aleatoric_relation_proof}
\citation{guo2017calibration}
\citation{Gal2016}
\citation{Geifman2019}
\citation{guo2017calibration}
\citation{Gal2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Summary of Work}{31}{subsection.4.1.2}\protected@file@percent }
\newlabel{subsec:selective_summary_of_work}{{4.1.2}{31}{Summary of Work}{subsection.4.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Literature Review}{32}{section.4.2}\protected@file@percent }
\newlabel{sec:selective_review}{{4.2}{32}{Literature Review}{section.4.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Asymmetrical Selective Classification}{32}{section.4.3}\protected@file@percent }
\newlabel{sec:selective_classification}{{4.3}{32}{Asymmetrical Selective Classification}{section.4.3}{}}
\citation{gal2016dropout}
\newlabel{fig:multiclasssymcosts}{{4.1a}{33}{\relax }{figure.caption.33}{}}
\newlabel{sub@fig:multiclasssymcosts}{{a}{33}{\relax }{figure.caption.33}{}}
\newlabel{fig:multiclassasymcosts}{{4.1b}{33}{\relax }{figure.caption.33}{}}
\newlabel{sub@fig:multiclassasymcosts}{{b}{33}{\relax }{figure.caption.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Cost matrices for the classes of the ISIC 2019 dataset. (a) Shows a symmetrical cost matrices where all costs of misclassification are equal. (b) shows a asymmetrical cost matrix where mis-classifications have different costs based on numerous factors.\relax }}{33}{figure.caption.33}\protected@file@percent }
\newlabel{fig:multiclasscosts}{{4.1}{33}{Cost matrices for the classes of the ISIC 2019 dataset. (a) Shows a symmetrical cost matrices where all costs of misclassification are equal. (b) shows a asymmetrical cost matrix where mis-classifications have different costs based on numerous factors.\relax }{figure.caption.33}{}}
\newlabel{eq:expected_cost_multi}{{4.1}{33}{Asymmetrical Selective Classification}{equation.4.3.1}{}}
\citation{guo2017calibration}
\citation{Liang2020Neural}
\citation{blundell2015weight}
\citation{mackay1992bayesian}
\citation{jospin2020hands}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Selective Classification Methods}{34}{section.4.4}\protected@file@percent }
\newlabel{sec:slective_classification_methods}{{4.4}{34}{Selective Classification Methods}{section.4.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Predictive Probabilities}{34}{subsection.4.4.1}\protected@file@percent }
\newlabel{subsec:selective_predictive_probabilites}{{4.4.1}{34}{Predictive Probabilities}{subsection.4.4.1}{}}
\newlabel{eq:softmax_response}{{4.2}{34}{Predictive Probabilities}{equation.4.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Calibrated Predictive Probabilities}{34}{subsection.4.4.2}\protected@file@percent }
\newlabel{subsec:selective_calibrated_probabilities}{{4.4.2}{34}{Calibrated Predictive Probabilities}{subsection.4.4.2}{}}
\newlabel{eq:selective_temperature_scaling}{{4.3}{34}{Calibrated Predictive Probabilities}{equation.4.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Bayesian Uncertainty}{34}{subsection.4.4.3}\protected@file@percent }
\newlabel{subsec:selective_uncertainity}{{4.4.3}{34}{Bayesian Uncertainty}{subsection.4.4.3}{}}
\citation{freeman1965elementary}
\citation{shannon1948mathematical}
\citation{houlsby2011bayesian}
\citation{Geifman2019Selective}
\newlabel{eq:avg_baysian_neural_network}{{4.4}{35}{Bayesian Uncertainty}{equation.4.4.4}{}}
\newlabel{eq:var_baysian_neural_network}{{4.5}{35}{Bayesian Uncertainty}{equation.4.4.5}{}}
\newlabel{eq:variation_ratio}{{4.6}{35}{Bayesian Uncertainty}{equation.4.4.6}{}}
\newlabel{eq:predictive_entropy}{{4.7}{35}{Bayesian Uncertainty}{equation.4.4.7}{}}
\newlabel{eq:mutual_information}{{4.8}{35}{Bayesian Uncertainty}{equation.4.4.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.4}SelectiveNet}{35}{subsection.4.4.4}\protected@file@percent }
\newlabel{subsec:selectivenet}{{4.4.4}{35}{SelectiveNet}{subsection.4.4.4}{}}
\citation{Geifman2019}
\citation{Geifman2019Selective}
\newlabel{eq:selective_loss}{{4.9}{36}{SelectiveNet}{equation.4.4.9}{}}
\newlabel{eq:selectivenet_loss}{{4.10}{36}{SelectiveNet}{equation.4.4.10}{}}
\newlabel{eq:selectivenet}{{4.11}{36}{SelectiveNet}{equation.4.4.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.5}Expected Cost SelectiveNet}{36}{subsection.4.4.5}\protected@file@percent }
\newlabel{subsec:ec_selectivenet}{{4.4.5}{36}{Expected Cost SelectiveNet}{subsection.4.4.5}{}}
\citation{codella2018skin,Combalia2019,Tschandl2018}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Binary Experiments}{37}{section.4.5}\protected@file@percent }
\newlabel{sec:selective_binary_experiment}{{4.5}{37}{Binary Experiments}{section.4.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Dataset}{37}{subsection.4.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Example images from the test data sets \(S_{in}\) and \(S_{unknown}\).\relax }}{37}{figure.caption.34}\protected@file@percent }
\newlabel{fig:isic_dataset_examples}{{4.2}{37}{Example images from the test data sets \(S_{in}\) and \(S_{unknown}\).\relax }{figure.caption.34}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}Experiment Setup}{38}{subsection.4.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.3}Training Parameters}{38}{subsection.4.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.4}Results}{38}{subsection.4.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{SelectiveNet: Effect of Target Coverage}{38}{section*.35}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Cost-coverage curves for SelectiveNets trained with different target coverages. From left to right: \(S_{in}\), \(S_{unknown}\) and \(S_{combined}\).\relax }}{38}{figure.caption.36}\protected@file@percent }
\newlabel{fig:sn_coverage}{{4.3}{38}{Cost-coverage curves for SelectiveNets trained with different target coverages. From left to right: \(S_{in}\), \(S_{unknown}\) and \(S_{combined}\).\relax }{figure.caption.36}{}}
\@writefile{toc}{\contentsline {subsubsection}{Does SelectiveNet Training Help?}{38}{section*.37}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{MC-Dropout, Temperature Scaling, and EC-SelectiveNet}{39}{section*.38}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Cost-coverage curves using MC-Dropout on $S_{in}$, $S_{unknown}$, and $S_{combined}$\relax }}{39}{figure.caption.39}\protected@file@percent }
\newlabel{fig:mc_dropout}{{4.4}{39}{Cost-coverage curves using MC-Dropout on $S_{in}$, $S_{unknown}$, and $S_{combined}$\relax }{figure.caption.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Cost-coverage curves. From left to right: \(S_{in}\), \(S_{unknown}\) and \(S_{combined}\).\relax }}{40}{figure.caption.40}\protected@file@percent }
\newlabel{fig:dataset_splits}{{4.5}{40}{Cost-coverage curves. From left to right: \(S_{in}\), \(S_{unknown}\) and \(S_{combined}\).\relax }{figure.caption.40}{}}
\@writefile{toc}{\contentsline {subsubsection}{Asymmetric Costs}{40}{section*.41}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Cost-coverage curves for SelectiveNet and EC-SelectiveNet. From left to right: $C_{1,0}=1$ (symmetric costs), $10$, and $50$ (highly asymmetric costs)\relax }}{40}{figure.caption.42}\protected@file@percent }
\newlabel{fig:sn_costs}{{4.6}{40}{Cost-coverage curves for SelectiveNet and EC-SelectiveNet. From left to right: $C_{1,0}=1$ (symmetric costs), $10$, and $50$ (highly asymmetric costs)\relax }{figure.caption.42}{}}
\citation{codella2018skin,combalia2019csn20000,tschandl2018the}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Cost-coverage curves for cross-entropy training and EC-SelectiveNet combined with temperature scaling. From left to right: $C_{1,0}=1$ (symmetric costs), $10$, and $50$ (highly asymmetric costs)\relax }}{41}{figure.caption.43}\protected@file@percent }
\newlabel{fig:temp_scaling}{{4.7}{41}{Cost-coverage curves for cross-entropy training and EC-SelectiveNet combined with temperature scaling. From left to right: $C_{1,0}=1$ (symmetric costs), $10$, and $50$ (highly asymmetric costs)\relax }{figure.caption.43}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Multi class Experiments}{41}{section.4.6}\protected@file@percent }
\newlabel{sec:selective_multi_class_experiments}{{4.6}{41}{Multi class Experiments}{section.4.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Dataset}{41}{subsection.4.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}Experiment Setup}{42}{subsection.4.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.3}Training Parameters}{42}{subsection.4.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.4}Results}{42}{subsection.4.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Conclusion}{42}{section.4.7}\protected@file@percent }
\newlabel{sec:selective_conclusion}{{4.7}{42}{Conclusion}{section.4.7}{}}
\citation{carse2022calibration}
\citation{maron2019systematic}
\citation{dai2020federated}
\citation{ulmer2020trust}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Predictive Probability Calibration}{43}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{ch:classification_claibration}{{5}{43}{Predictive Probability Calibration}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Introduction}{43}{section.5.1}\protected@file@percent }
\newlabel{sec:calibration_introduction}{{5.1}{43}{Introduction}{section.5.1}{}}
\citation{guo2017calibration}
\citation{mukhoti2020calibrating,frenkel2021network}
\citation{guo2017calibration}
\citation{muller2019does}
\citation{roelofs2022mitigating}
\citation{parzen1962estimation}
\citation{gawlikowski2021survey}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Measures of Calibration}{45}{section.5.2}\protected@file@percent }
\newlabel{sec:calibration_measures}{{5.2}{45}{Measures of Calibration}{section.5.2}{}}
\citation{hendrycks2019augmix}
\citation{hendrycks2018deep}
\citation{szegedy2016rethinking}
\citation{islam2021spatially}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Example reliability diagram.\relax }}{46}{figure.caption.44}\protected@file@percent }
\newlabel{fig:reliability_diagram}{{5.1}{46}{Example reliability diagram.\relax }{figure.caption.44}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Calibration Methods and Literature Review}{46}{section.5.3}\protected@file@percent }
\newlabel{sec:calibration_review}{{5.3}{46}{Calibration Methods and Literature Review}{section.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Model Regularisation For Calibration}{46}{subsection.5.3.1}\protected@file@percent }
\citation{lin2017focal}
\citation{mukhoti2020calibrating}
\citation{guo2017calibration,liang2020improved}
\citation{platt1999probabilistic}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Post-Hoc Calibration}{47}{subsection.5.3.2}\protected@file@percent }
\citation{kwon2020uncertainty}
\newlabel{eq:temperature_scaling}{{5.1}{48}{Post-Hoc Calibration}{equation.5.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Bayesian Approximation}{48}{subsection.5.3.3}\protected@file@percent }
\newlabel{subsec:bayesian_calibration}{{5.3.3}{48}{Bayesian Approximation}{subsection.5.3.3}{}}
\newlabel{eq:elbo}{{5.2}{48}{Bayesian Approximation}{equation.5.3.2}{}}
\citation{mackay1992bayesian,botev2017practical}
\citation{daxberger2021laplace}
\citation{codella2018skin,combalia2019bcn20000,tschandl2018ham10000}
\citation{veeling2018rotation}
\citation{bejnordi2017diagnostic}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Calibration Experiments}{49}{section.5.4}\protected@file@percent }
\newlabel{sec:calibration_experiments}{{5.4}{49}{Calibration Experiments}{section.5.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Datasets}{49}{subsection.5.4.1}\protected@file@percent }
\citation{liu1989limited}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Example Images from the ISIC Challenge 2019 dataset.\relax }}{50}{figure.caption.45}\protected@file@percent }
\newlabel{fig:ISIC_examples}{{5.2}{50}{Example Images from the ISIC Challenge 2019 dataset.\relax }{figure.caption.45}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Experiment Setup}{50}{subsection.5.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.3}Training Parameters}{51}{subsection.5.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.4}Results}{51}{subsection.5.4.4}\protected@file@percent }
\newlabel{subsec:calibration_results}{{5.4.4}{51}{Results}{subsection.5.4.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Calibration and accuracy results for ISIC 2019 and PCam datasets. ISIC 2019 results are means and standard deviations over three iterations. Each section reports results from a single model type; TS denotes temperature scaling.\relax }}{52}{table.caption.46}\protected@file@percent }
\newlabel{tab:calibration_results}{{5.1}{52}{Calibration and accuracy results for ISIC 2019 and PCam datasets. ISIC 2019 results are means and standard deviations over three iterations. Each section reports results from a single model type; TS denotes temperature scaling.\relax }{table.caption.46}{}}
\citation{mukhoti2020calibrating}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Conclusion}{54}{section.5.5}\protected@file@percent }
\newlabel{sec:calibration_conclusion}{{5.5}{54}{Conclusion}{section.5.5}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion and Discussion}{55}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{ch:conclusion_and_discussion}{{6}{55}{Conclusion and Discussion}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Pathway to Complete System}{55}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Summary of Contributions}{55}{section.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Limitations}{55}{section.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Future Work}{55}{section.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.1}Active Learning}{55}{subsection.6.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.2}Unsupervised Learning}{55}{subsection.6.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.3}Selective Classification}{55}{subsection.6.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.4}Asymmetrical Risks}{56}{subsection.6.4.4}\protected@file@percent }
\bibdata{refs/intro,refs/active,refs/unsupervised,refs/calibration,refs/selective}
\bibcite{bejnordi2017diagnostic}{{1}{2017}{{Bejnordi et~al.}}{{Bejnordi, Veta, Van~Diest, Van~Ginneken, Karssemeijer, Litjens, Van Der~Laak, Hermsen, Manson, Balkenhol et~al.}}}
\bibcite{bengio2013representation}{{2}{2013}{{Bengio et~al.}}{{Bengio, Courville \&\ Vincent}}}
\bibcite{blundell2015weight}{{3}{2015}{{Blundell et~al.}}{{Blundell, Cornebise, Kavukcuoglu \&\ Wierstra}}}
\bibcite{botev2017practical}{{4}{2017}{{Botev et~al.}}{{Botev, Ritter \&\ Barber}}}
\bibcite{carse2022calibration}{{5}{2022}{{Carse et~al.}}{{Carse, Alvarez~Olmo \&\ McKenna}}}
\bibcite{carse2021unsupervised}{{6}{2021}{{Carse, Carey \&\ McKenna}}{{}}}
\bibcite{carse2019active}{{7}{2019}{{Carse \&\ McKenna}}{{}}}
\bibcite{carse2021robust}{{8}{2021}{{Carse, S{\"u}veges, Hogg, Trucco, Proby, Fleming \&\ McKenna}}{{}}}
\@writefile{toc}{\contentsline {chapter}{References}{57}{subsection.6.4.4}\protected@file@percent }
\bibcite{chen2014cross}{{9}{2014}{{Chen et~al.}}{{Chen, Chen \&\ Hsu}}}
\bibcite{codella2018skin}{{10}{2018}{{Codella et~al.}}{{Codella, Gutman, Celebi, Helba, Marchetti, Dusza, Kalloo, Liopyris, Mishra, Kittler et~al.}}}
\bibcite{cohen2017emnist}{{11}{2017}{{Cohen et~al.}}{{Cohen, Afshar, Tapson \&\ Van~Schaik}}}
\bibcite{cohn1996active}{{12}{1996}{{Cohn et~al.}}{{Cohn, Ghahramani \&\ Jordan}}}
\bibcite{Combalia2019}{{13}{2019{\em  a}}{{Combalia, M. and Codella, N. C. and Rotemberg, V. and Helba, B. and Vilaplana, V. and Reiter, O., and others}}{{}}}
\bibcite{combalia2019csn20000}{{14}{2019{\em  b}}{{Combalia, M. and Codella, N. C. and Rotemberg, V. and Helba, B. and Vilaplana, V. and Reiter, O., and others}}{{}}}
\bibcite{combalia2019bcn20000}{{15}{2019}{{Combalia et~al.}}{{Combalia, Codella, Rotemberg, Helba, Vilaplana, Reiter, Carrera, Barreiro, Halpern, Puig et~al.}}}
\bibcite{dai2020federated}{{16}{2020}{{Dai et~al.}}{{Dai, Low \&\ Jaillet}}}
\bibcite{darlow2018cinic}{{17}{2018}{{Darlow et~al.}}{{Darlow, Crowley, Antoniou \&\ Storkey}}}
\bibcite{daxberger2021laplace}{{18}{2021}{{Daxberger et~al.}}{{Daxberger, Kristiadi, Immer, Eschenhagen, Bauer \&\ Hennig}}}
\bibcite{demir2015novel}{{19}{2015}{{Demir \&\ Bruzzone}}{{}}}
\bibcite{deng2009imagenet}{{20}{2009}{{Deng et~al.}}{{Deng, Dong, Socher, Li, Li \&\ Fei-Fei}}}
\bibcite{ducoffe2018adversarial}{{21}{2018}{{Ducoffe \&\ Precioso}}{{}}}
\bibcite{farahani2009facility}{{22}{2009}{{Farahani \&\ Hekmatfar}}{{}}}
\bibcite{freeman1965elementary}{{23}{1965}{{Freeman}}{{}}}
\bibcite{frenkel2021network}{{24}{2021}{{Frenkel \&\ Goldberger}}{{}}}
\bibcite{gal2016dropout}{{25}{2016{\em  a}}{{Gal \&\ Ghahramani}}{{}}}
\bibcite{Gal2016}{{26}{2016{\em  b}}{{Gal \&\ Ghahramani}}{{}}}
\bibcite{gal2017deep}{{27}{2017}{{Gal et~al.}}{{Gal, Islam \&\ Ghahramani}}}
\bibcite{gawlikowski2021survey}{{28}{2021}{{Gawlikowski et~al.}}{{Gawlikowski, Tassi, Ali, Lee, Humt, Feng, Kruspe, Triebel, Jung, Roscher et~al.}}}
\bibcite{Geifman2019}{{29}{2019{\em  a}}{{Geifman \&\ El-Yaniv}}{{}}}
\bibcite{Geifman2019Selective}{{30}{2019{\em  b}}{{Geifman \&\ El-Yaniv}}{{}}}
\bibcite{glorot2010understanding}{{31}{2010}{{Glorot \&\ Bengio}}{{}}}
\bibcite{guo2017calibration}{{32}{2017}{{Guo et~al.}}{{Guo, Pleiss, Sun \&\ Weinberger}}}
\bibcite{gutman2016skin}{{33}{2016}{{Gutman et~al.}}{{Gutman, Codella, Celebi, Helba, Marchetti, Mishra \&\ Halpern}}}
\bibcite{gutmann2010noise}{{34}{2010}{{Gutmann \&\ Hyv{\"a}rinen}}{{}}}
\bibcite{henaff2019data}{{35}{2019}{{H\'enaff et~al.}}{{H\'enaff, Srinivas, Fauw, Razavi, Doersch, Eslami \&\ van~den Oord}}}
\bibcite{hendrycks2018deep}{{36}{2018}{{Hendrycks et~al.}}{{Hendrycks, Mazeika \&\ Dietterich}}}
\bibcite{hendrycks2019augmix}{{37}{2019}{{Hendrycks et~al.}}{{Hendrycks, Mu, Cubuk, Zoph, Gilmer \&\ Lakshminarayanan}}}
\bibcite{houlsby2011bayesian}{{38}{2011}{{Houlsby et~al.}}{{Houlsby, Husz{\'a}r, Ghahramani \&\ Lengyel}}}
\bibcite{islam2021spatially}{{39}{2021}{{Islam \&\ Glocker}}{{}}}
\bibcite{jospin2020hands}{{40}{2020}{{Jospin et~al.}}{{Jospin, Buntine, Boussaid, Laga \&\ Bennamoun}}}
\bibcite{kampffmeyer2016semantic}{{41}{2016}{{Kampffmeyer et~al.}}{{Kampffmeyer, Salberg \&\ Jenssen}}}
\bibcite{kingma2014adam}{{42}{2014}{{Kingma \&\ Ba}}{{}}}
\bibcite{kirsch2019batchbald}{{43}{2019}{{Kirsch et~al.}}{{Kirsch, Van~Amersfoort \&\ Gal}}}
\bibcite{krizhevsky2009learning}{{44}{2009}{{Krizhevsky \&\ Hinton}}{{}}}
\bibcite{kurakin2016adversarial}{{45}{2016}{{Kurakin et~al.}}{{Kurakin, Goodfellow \&\ Bengio}}}
\bibcite{kwon2020uncertainty}{{46}{2020}{{Kwon et~al.}}{{Kwon, Won, Kim \&\ Paik}}}
\bibcite{lecun1998gradient}{{47}{1998}{{LeCun et~al.}}{{LeCun, Bottou, Bengio \&\ Haffner}}}
\bibcite{lee2013pseudo}{{48}{2013}{{Lee}}{{}}}
\bibcite{lewis1995sequential}{{49}{1995}{{Lewis}}{{}}}
\bibcite{Liang2020Neural}{{50}{2020}{{Liang, Zhang \&\ Jacobs}}{{}}}
\bibcite{liang2020improved}{{51}{2020}{{Liang, Zhang, Wang \&\ Jacobs}}{{}}}
\bibcite{lin2017focal}{{52}{2017}{{Lin et~al.}}{{Lin, Goyal, Girshick, He \&\ Doll{\'a}r}}}
\bibcite{litjens20181399}{{53}{2018}{{Litjens et~al.}}{{Litjens, Bandi, Bejnordi, Geessink, Balkenhol, Bult, Halilovic, Hermsen, van~de Loo, Vogels, Manson, Stathonikos, Baidoshvili, van Diest, Wauters, van Dijk \&\ van~der Laak}}}
\bibcite{litjens2017survey}{{54}{2017}{{Litjens et~al.}}{{Litjens, Kooi, Bejnordi, Setio, Ciompi, Ghafoorian, Van Der~Laak, Van~Ginneken \&\ S{\'a}nchez}}}
\bibcite{liu1989limited}{{55}{1989}{{Liu \&\ Nocedal}}{{}}}
\bibcite{mackay1992bayesian}{{56}{1992}{{MacKay}}{{}}}
\bibcite{madabhushi2016image}{{57}{2016}{{Madabhushi \&\ Lee}}{{}}}
\bibcite{maron2019systematic}{{58}{2019}{{Maron et~al.}}{{Maron, Weichenthal, Utikal, Hekler, Berking, Hauschild, Enk, Haferkamp, Klode, Schadendorf et~al.}}}
\bibcite{aleatoric_relation_proof}{{59}{2021}{{Mohseni et~al.}}{{Mohseni, Yap, Yolland, Razmara \&\ Atkins}}}
\bibcite{mukhoti2020calibrating}{{60}{2020}{{Mukhoti et~al.}}{{Mukhoti, Kulharia, Sanyal, Golodetz, Torr \&\ Dokania}}}
\bibcite{muller2019does}{{61}{2019}{{M{\"u}ller et~al.}}{{M{\"u}ller, Kornblith \&\ Hinton}}}
\bibcite{parzen1962estimation}{{62}{1962}{{Parzen}}{{}}}
\bibcite{platt1999probabilistic}{{63}{1999}{{Platt et~al.}}{{}}}
\bibcite{pop2018deep}{{64}{2018}{{Pop \&\ Fulop}}{{}}}
\bibcite{prechelt1998early}{{65}{1998}{{Prechelt}}{{}}}
\bibcite{rasmus2015semi}{{66}{2015}{{Rasmus et~al.}}{{Rasmus, Berglund, Honkala, Valpola \&\ Raiko}}}
\bibcite{ren2021survey}{{67}{2021}{{Ren et~al.}}{{Ren, Xiao, Chang, Huang, Li, Gupta, Chen \&\ Wang}}}
\bibcite{roelofs2022mitigating}{{68}{2022}{{Roelofs et~al.}}{{Roelofs, Cain, Shlens \&\ Mozer}}}
\bibcite{roy2001toward}{{69}{2001}{{Roy \&\ McCallum}}{{}}}
\bibcite{sener2017active}{{70}{2017}{{Sener \&\ Savarese}}{{}}}
\bibcite{settles2012active}{{71}{2012}{{Settles}}{{}}}
\bibcite{settles2008analysis}{{72}{2008}{{Settles \&\ Craven}}{{}}}
\bibcite{settles2007multiple}{{73}{2007}{{Settles et~al.}}{{Settles, Craven \&\ Ray}}}
\bibcite{seung1992query}{{74}{1992}{{Seung et~al.}}{{Seung, Opper \&\ Sompolinsky}}}
\bibcite{shannon1948mathematical}{{75}{1948}{{Shannon}}{{}}}
\bibcite{shao2018deep}{{76}{2018}{{Shao et~al.}}{{Shao, Sun \&\ Zhang}}}
\bibcite{shin1949mathematical}{{77}{1949}{{Shin \&\ Kim}}{{}}}
\bibcite{sirinukunwattana2016locality}{{78}{2016}{{Sirinukunwattana et~al.}}{{Sirinukunwattana, Raza, Tsang, Snead, Cree \&\ Rajpoot}}}
\bibcite{srivastava2014dropout}{{79}{2014}{{Srivastava et~al.}}{{Srivastava, Hinton, Krizhevsky, Sutskever \&\ Salakhutdinov}}}
\bibcite{szegedy2016rethinking}{{80}{2016}{{Szegedy et~al.}}{{Szegedy, Vanhoucke, Ioffe, Shlens \&\ Wojna}}}
\bibcite{tan2019efficientnet}{{81}{2019}{{Tan \&\ Le}}{{}}}
\bibcite{tizhoosh2018artificial}{{82}{2018}{{Tizhoosh \&\ Pantanowitz}}{{}}}
\bibcite{tschandl2018ham10000}{{83}{2018{\em  a}}{{Tschandl et~al.}}{{Tschandl, Rosendahl \&\ Kittler}}}
\bibcite{Tschandl2018}{{84}{2018{\em  b}}{{Tschandl et~al.}}{{Tschandl, Rosendahl \&\ Kittler}}}
\bibcite{tschandl2018the}{{85}{2018{\em  c}}{{Tschandl et~al.}}{{Tschandl, Rosendahl \&\ Kittler}}}
\bibcite{ulmer2020trust}{{86}{2020}{{Ulmer et~al.}}{{Ulmer, Meijerink \&\ Cin{\`a}}}}
\bibcite{oord2016pixel}{{87}{2016}{{van~den Oord et~al.}}{{van~den Oord, Kalchbrenner \&\ Kavukcuoglu}}}
\bibcite{oord2018representation}{{88}{2018}{{van~den Oord et~al.}}{{van~den Oord, Li \&\ Vinyals}}}
\bibcite{veeling2018rotation}{{89}{2018}{{Veeling et~al.}}{{Veeling, Linmans, Winkens, Cohen \&\ Welling}}}
\bibcite{wang2017cost}{{90}{2017}{{Wang et~al.}}{{Wang, Zhang, Li, Zhang \&\ Lin}}}
\bibcite{weiss2016survey}{{91}{2016}{{Weiss et~al.}}{{Weiss, Khoshgoftaar \&\ Wang}}}
\bibcite{xie2017aggregated}{{92}{2017}{{Xie et~al.}}{{Xie, Girshick, Doll{\'a}r, Tu \&\ He}}}
\bibcite{zeiler2012adadelta}{{93}{2012}{{Zeiler}}{{}}}
\bibcite{zhang2020mix}{{94}{2020}{{Zhang et~al.}}{{Zhang, Kailkhura \&\ Han}}}
\bibcite{zhdanov2019diverse}{{95}{2019}{{Zhdanov}}{{}}}
\@writefile{toc}{\contentsline {chapter}{Appendices}{67}{section*.48}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {A}List of Publications and Achievements}{68}{appendix.a.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{app:list_of_publications}{{A}{68}{List of Publications and Achievements}{appendix.a.A}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}First Authored Publications}{68}{section.a.A.1}\protected@file@percent }
\newlabel{sec:first_authored_publications}{{A.1}{68}{First Authored Publications}{section.a.A.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.2}Contributed Publications}{69}{section.a.A.2}\protected@file@percent }
\newlabel{sec:contributed_publications}{{A.2}{69}{Contributed Publications}{section.a.A.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.3}Awards}{69}{section.a.A.3}\protected@file@percent }
\newlabel{sec:awards}{{A.3}{69}{Awards}{section.a.A.3}{}}
\gdef \@abspage@last{83}
