\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{agsm}
\providecommand \oddpage@label [2]{}
\citation{sener2017active}
\citation{sirinukunwattana2016locality}
\citation{deng2009imagenet}
\citation{veeling2018rotation}
\citation{veeling2018rotation,litjens20181399}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{v}{chapter*.1}\protected@file@percent }
\citation{codella2018skin,combalia2019bcn20000,tschandl2018ham10000}
\citation{yang2019self}
\@writefile{toc}{\contentsline {chapter}{List of Tables}{vii}{chapter*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{List of Terms}{viii}{chapter*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{List of Abbreviations}{ix}{chapter*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{List of Symbols}{x}{chapter*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Acknowledgements}{xi}{chapter*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Declaration}{xii}{chapter*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Abstract}{xiii}{chapter*.10}\protected@file@percent }
\citation{litjens2017survey}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{ch:introduction}{{1}{1}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Introduction to Problem}{1}{section.1.1}\protected@file@percent }
\newlabel{sec:intoduction_to_problem}{{1.1}{1}{Introduction to Problem}{section.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Research Contributions}{1}{section.1.2}\protected@file@percent }
\newlabel{sec:research_contributions}{{1.2}{1}{Research Contributions}{section.1.2}{}}
\citation{tizhoosh2018artificial}
\citation{settles2012active}
\citation{carse2019active}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Thesis Structure}{2}{section.1.3}\protected@file@percent }
\newlabel{sec:thesis_structure}{{1.3}{2}{Thesis Structure}{section.1.3}{}}
\citation{maron2019systematic}
\citation{guo2017calibration}
\citation{carse2021robust}
\citation{carse2022calibration}
\citation{carse2019active}
\citation{settles2012active}
\citation{gal2017deep}
\citation{pop2018deep}
\citation{sener2017active,zhdanov2019diverse,kirsch2019batchbald}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Annotator Efficient Active Learning}{6}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{ch:active_learning}{{2}{6}{Annotator Efficient Active Learning}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Introduction}{6}{section.2.1}\protected@file@percent }
\newlabel{sec:active_introduction}{{2.1}{6}{Introduction}{section.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Active Learning for Medical Image Analysis}{6}{subsection.2.1.1}\protected@file@percent }
\newlabel{subsec:active_for_medical_image_analysis}{{2.1.1}{6}{Active Learning for Medical Image Analysis}{subsection.2.1.1}{}}
\citation{sirinukunwattana2016locality}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Pool-based active learning framework.\relax }}{7}{figure.caption.17}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:pool_based_active_learning}{{2.1}{7}{Pool-based active learning framework.\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Deep Active Learning for Digital Pathology}{7}{subsection.2.1.2}\protected@file@percent }
\newlabel{subsec:active_deep_learning}{{2.1.2}{7}{Deep Active Learning for Digital Pathology}{subsection.2.1.2}{}}
\citation{settles2012active}
\citation{lewis1995sequential}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Active Learning for Medical Images Review}{8}{section.2.2}\protected@file@percent }
\newlabel{sec:active_review}{{2.2}{8}{Active Learning for Medical Images Review}{section.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Pool-Based Active Learning Query Strategies}{8}{subsection.2.2.1}\protected@file@percent }
\newlabel{subsec:active_pool_based}{{2.2.1}{8}{Pool-Based Active Learning Query Strategies}{subsection.2.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Traditional Machine Learning Query Strategies}{8}{section*.18}\protected@file@percent }
\citation{seung1992query}
\citation{settles2007multiple}
\citation{roy2001toward}
\citation{cohn1996active}
\citation{settles2008analysis}
\citation{ren2021survey}
\@writefile{toc}{\contentsline {subsubsection}{Deep Learning Query Strategies}{9}{section*.19}\protected@file@percent }
\citation{wang2017cost}
\citation{lee2013pseudo}
\citation{demir2015novel}
\citation{chen2014cross}
\citation{gal2016dropout}
\citation{gal2017deep}
\citation{shin1949mathematical}
\citation{freeman1965elementary}
\citation{kampffmeyer2016semantic}
\citation{houlsby2011bayesian}
\citation{gutman2016skin}
\@writefile{toc}{\contentsline {subsubsection}{Scoring Query Strategies}{10}{section*.20}\protected@file@percent }
\newlabel{eq:bayesian_cnn}{{2.1}{10}{Scoring Query Strategies}{equation.2.2.1}{}}
\citation{ducoffe2018adversarial}
\citation{settles2012active}
\citation{kurakin2016adversarial}
\citation{sener2017active}
\citation{farahani2009facility}
\citation{sener2017active}
\citation{sener2017active}
\citation{rasmus2015semi}
\citation{krizhevsky2009learning}
\@writefile{toc}{\contentsline {subsubsection}{Batch Aware Query Strategies}{11}{section*.21}\protected@file@percent }
\citation{kirsch2019batchbald}
\citation{gal2017deep}
\citation{lecun1998gradient}
\citation{cohen2017emnist}
\citation{darlow2018cinic}
\citation{zhdanov2019diverse}
\citation{lecun1998gradient}
\citation{krizhevsky2009learning}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces A visual illustration of the core-sets query strategy, in which four points are selected that cover all other data points and minimize $\delta _s$\nobreakspace  {}\citep  {sener2017active}.\relax }}{12}{figure.caption.22}\protected@file@percent }
\newlabel{fig:core-set}{{2.2}{12}{A visual illustration of the core-sets query strategy, in which four points are selected that cover all other data points and minimize $\delta _s$~\citep {sener2017active}.\relax }{figure.caption.22}{}}
\citation{budd2021survey}
\citation{gamper2019pannuke,gamper2020pannuke}
\citation{budd2021survey}
\citation{konyushkova2019geometry,zhao2019data}
\citation{shi2019active,gorriz2017cost}
\citation{liu2020semi}
\citation{folmsbee2021whole,jin2021reducing}
\citation{settles2008active2}
\citation{mackowiak2018cereals}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Application of Active Learning for Medicine}{13}{subsection.2.2.2}\protected@file@percent }
\newlabel{subsec:active_applications}{{2.2.2}{13}{Application of Active Learning for Medicine}{subsection.2.2.2}{}}
\citation{gal2016dropout}
\citation{cordts2016cityscapes}
\citation{colling2020metabox}
\citation{sirinukunwattana2016locality}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Active Learning for Annotation Efficiency}{14}{subsection.2.2.3}\protected@file@percent }
\newlabel{subsec:active_annotation_efficiency}{{2.2.3}{14}{Active Learning for Annotation Efficiency}{subsection.2.2.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Annotator Efficient Active Learning for Histopathology}{14}{section.2.3}\protected@file@percent }
\newlabel{sec:active_annotator_efficient}{{2.3}{14}{Annotator Efficient Active Learning for Histopathology}{section.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Region-Based Active Learning}{15}{subsection.2.3.1}\protected@file@percent }
\newlabel{subsec:active_region_based}{{2.3.1}{15}{Region-Based Active Learning}{subsection.2.3.1}{}}
\citation{sirinukunwattana2016locality}
\citation{shao2018deep}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Region-based active learning\relax }}{16}{algocf.1}\protected@file@percent }
\newlabel{alg:regionbased}{{1}{16}{Region-Based Active Learning}{algocf.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Active Learning Experiments}{16}{section.2.4}\protected@file@percent }
\newlabel{sec:active_experiments}{{2.4}{16}{Active Learning Experiments}{section.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Dataset}{16}{subsection.2.4.1}\protected@file@percent }
\newlabel{subsec:active_dataset}{{2.4.1}{16}{Dataset}{subsection.2.4.1}{}}
\citation{sirinukunwattana2016locality}
\citation{sirinukunwattana2016locality}
\citation{sirinukunwattana2016locality}
\citation{srivastava2014dropout}
\citation{zeiler2012adadelta}
\citation{prechelt1998early}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Three example regions from the CRCHistoPhenotypes dataset\nobreakspace  {}\cite  {sirinukunwattana2016locality} are shown, each containing multiple nuclei that will be extracted into patches and augmented.\relax }}{17}{figure.caption.24}\protected@file@percent }
\newlabel{fig:region_example}{{2.3}{17}{Three example regions from the CRCHistoPhenotypes dataset~\cite {sirinukunwattana2016locality} are shown, each containing multiple nuclei that will be extracted into patches and augmented.\relax }{figure.caption.24}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Training Parameters}{17}{subsection.2.4.2}\protected@file@percent }
\newlabel{subsec:active_training}{{2.4.2}{17}{Training Parameters}{subsection.2.4.2}{}}
\citation{sener2017active}
\citation{gal2017deep}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces The Convolutional Neural Network architecture employed for nuclei classification in the region-based active learning experiments.\relax }}{18}{table.caption.25}\protected@file@percent }
\newlabel{tab:active_learning_cnn}{{2.1}{18}{The Convolutional Neural Network architecture employed for nuclei classification in the region-based active learning experiments.\relax }{table.caption.25}{}}
\newlabel{eq:generalization_loss}{{2.2}{18}{Training Parameters}{equation.2.4.2}{}}
\newlabel{eq:training_progression}{{2.3}{18}{Training Parameters}{equation.2.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Experiment Setup}{18}{subsection.2.4.3}\protected@file@percent }
\newlabel{subsec:active_experiments}{{2.4.3}{18}{Experiment Setup}{subsection.2.4.3}{}}
\citation{glorot2010understanding}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.4}Results}{19}{subsection.2.4.4}\protected@file@percent }
\newlabel{subsec:active_results}{{2.4.4}{19}{Results}{subsection.2.4.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Test results for each query strategy after 50 active iterations.\relax }}{19}{table.caption.26}\protected@file@percent }
\newlabel{tab:query_results}{{2.2}{19}{Test results for each query strategy after 50 active iterations.\relax }{table.caption.26}{}}
\citation{ren2021survey}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Average test accuracy of trained models using different amounts of annotated regions selected through various query strategies.\relax }}{20}{figure.caption.27}\protected@file@percent }
\newlabel{fig:active_learning_accuracy}{{2.4}{20}{Average test accuracy of trained models using different amounts of annotated regions selected through various query strategies.\relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Conclusion}{20}{section.2.5}\protected@file@percent }
\newlabel{sec:active_conclusion}{{2.5}{20}{Conclusion}{section.2.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Average test mean class accuracy of trained models using different amounts of annotated regions selected through various query strategies.\relax }}{21}{figure.caption.28}\protected@file@percent }
\newlabel{fig:active_learning_mean_class_accuracy}{{2.5}{21}{Average test mean class accuracy of trained models using different amounts of annotated regions selected through various query strategies.\relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Average test loss of trained models using different amounts of annotated regions selected through various query strategies.\relax }}{21}{figure.caption.29}\protected@file@percent }
\newlabel{fig:active_learning_loss}{{2.6}{21}{Average test loss of trained models using different amounts of annotated regions selected through various query strategies.\relax }{figure.caption.29}{}}
\citation{litjens2017survey}
\citation{madabhushi2016image}
\citation{bengio2013representation}
\citation{deng2009imagenet}
\citation{veeling2018rotation}
\citation{deng2009imagenet}
\citation{veeling2018rotation}
\citation{weiss2016survey}
\citation{oord2018representation}
\citation{henaff2019data}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Unsupervised Representation Learning}{23}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{ch:unsupervised_representation_learning}{{3}{23}{Unsupervised Representation Learning}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Introduction}{23}{section.3.1}\protected@file@percent }
\newlabel{sec:unsupervised_intro}{{3.1}{23}{Introduction}{section.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces (a) An example image from the ImageNet dataset\nobreakspace  {}\citep  {deng2009imagenet}. (b) Extracted overlapping patches with those used to produce context and autoregressor direction highlighted. (c) An example image from the Patch Camelyon dataset\nobreakspace  {}\citep  {veeling2018rotation}. (d) Extracted overlapping patches with those used to produce context and autoregressor direction highlighted.\relax }}{24}{figure.caption.30}\protected@file@percent }
\newlabel{fig:example_cpc_patches}{{3.1}{24}{(a) An example image from the ImageNet dataset~\citep {deng2009imagenet}. (b) Extracted overlapping patches with those used to produce context and autoregressor direction highlighted. (c) An example image from the Patch Camelyon dataset~\citep {veeling2018rotation}. (d) Extracted overlapping patches with those used to produce context and autoregressor direction highlighted.\relax }{figure.caption.30}{}}
\citation{oord2016pixel}
\citation{veeling2018rotation}
\citation{litjens20181399}
\citation{carse2021unsupervised}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Proposed active learning framework with learnt representations from unsupervised representation learning on unannotated data.\relax }}{25}{figure.caption.31}\protected@file@percent }
\newlabel{fig:active_unsupervised_learning_framework}{{3.2}{25}{Proposed active learning framework with learnt representations from unsupervised representation learning on unannotated data.\relax }{figure.caption.31}{}}
\citation{carse2021unsupervised}
\citation{lake2015human}
\citation{weiss2016survey}
\citation{bengio2013representation}
\citation{kaji2019overview}
\citation{yi2019generative}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Unsupervised Representation Learning for Computer Vision}{26}{section.3.2}\protected@file@percent }
\newlabel{subsec:unsupervised_representation}{{3.2}{26}{Unsupervised Representation Learning for Computer Vision}{section.3.2}{}}
\citation{kramer1991nonlinear}
\citation{goodfellow2016deep}
\citation{makhzani2013k}
\citation{bengio2013generalized}
\citation{kingma2013auto}
\citation{kullback1951information}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Generative Methods}{27}{subsection.3.2.1}\protected@file@percent }
\newlabel{subsec:generative_methods}{{3.2.1}{27}{Generative Methods}{subsection.3.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Autoencoders}{27}{section*.32}\protected@file@percent }
\newlabel{subsubsec:autoencoders}{{3.2.1}{27}{Autoencoders}{section*.32}{}}
\citation{wei2020recent}
\citation{akrami2020brain}
\citation{thiagarajan2020improving}
\citation{goodfellow2014advances}
\citation{arjovsky2017wasserstein}
\citation{gulrajani2017improved}
\citation{srivastav2021improved}
\citation{mukherjee2019clustergan}
\@writefile{toc}{\contentsline {subsubsection}{Generative Adversarial Networks}{28}{section*.33}\protected@file@percent }
\newlabel{subsubsec:generative_adversarial_networks}{{3.2.1}{28}{Generative Adversarial Networks}{section*.33}{}}
\citation{donahue2019large}
\citation{donahue2016adversarial}
\citation{shurrab2022self}
\citation{gidaris2018unsupervised}
\citation{zhou2021preservational}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Self-supervised Methods}{29}{subsection.3.2.2}\protected@file@percent }
\newlabel{subsec:self_supervised_methods}{{3.2.2}{29}{Self-supervised Methods}{subsection.3.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{RotNet}{29}{section*.34}\protected@file@percent }
\newlabel{subsubsec:RotNet}{{3.2.2}{29}{RotNet}{section*.34}{}}
\citation{caron2018deep}
\citation{wu2018unsupervised}
\citation{gutmann2010noise}
\citation{parikh2014proximal}
\citation{zhuang2019local}
\citation{deng2009imagenet}
\@writefile{toc}{\contentsline {subsubsection}{Deep Clustering}{30}{section*.35}\protected@file@percent }
\newlabel{subsubsec:deep_clustering}{{3.2.2}{30}{Deep Clustering}{section*.35}{}}
\@writefile{toc}{\contentsline {subsubsection}{Non-Parametric Instance-Level Discrimination}{30}{section*.36}\protected@file@percent }
\newlabel{subsubsec:non-parametric_instance-level_discrimination}{{3.2.2}{30}{Non-Parametric Instance-Level Discrimination}{section*.36}{}}
\@writefile{toc}{\contentsline {subsubsection}{Local Aggregation}{30}{section*.37}\protected@file@percent }
\newlabel{subsubsec:local_aggregation}{{3.2.2}{30}{Local Aggregation}{section*.37}{}}
\citation{he2020momentum}
\citation{misra2020self}
\citation{gutmann2010noise}
\citation{he2016deep}
\citation{noroozi2016unsupervised}
\@writefile{toc}{\contentsline {subsubsection}{Momentum Contrast}{31}{section*.38}\protected@file@percent }
\newlabel{subsubsec:momentum_contrast}{{3.2.2}{31}{Momentum Contrast}{section*.38}{}}
\@writefile{toc}{\contentsline {subsubsection}{Pretext-Invariant Representations}{31}{section*.39}\protected@file@percent }
\newlabel{subsubsec:pretext_invariant_representations}{{3.2.2}{31}{Pretext-Invariant Representations}{section*.39}{}}
\citation{hjelm2018learning}
\citation{shannon1948mathematical}
\citation{bachman2019learning}
\citation{srinidhi2020deep}
\citation{bayramoglu2016transfer}
\citation{hou2016automatic}
\citation{carse2019active}
\@writefile{toc}{\contentsline {subsubsection}{Deep InfoMax}{32}{section*.40}\protected@file@percent }
\newlabel{subsubsec:DIM}{{3.2.2}{32}{Deep InfoMax}{section*.40}{}}
\citation{hu2018unsupervised}
\citation{chang2017unsupervised}
\citation{henaff2019data,oord2018representation}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Unsupervised Representation Learning for \\Medical Image Analysis}{33}{subsection.3.2.3}\protected@file@percent }
\newlabel{subsec:unsupervise_representation_for_medical}{{3.2.3}{33}{Unsupervised Representation Learning for \\Medical Image Analysis}{subsection.3.2.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Multi-Directional Contrastive Predictive Coding}{33}{section.3.3}\protected@file@percent }
\newlabel{sec:unsupervised_multi_directional_cpc}{{3.3}{33}{Multi-Directional Contrastive Predictive Coding}{section.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Contrastive Predictive Coding}{33}{subsection.3.3.1}\protected@file@percent }
\newlabel{subsec:unsupervised_cpc}{{3.3.1}{33}{Contrastive Predictive Coding}{subsection.3.3.1}{}}
\citation{gutmann2010noise}
\citation{oord2018representation}
\citation{deng2009imagenet}
\newlabel{eq:density_ratio}{{3.1}{34}{Contrastive Predictive Coding}{equation.3.3.1}{}}
\newlabel{eq:InfoNCE}{{3.2}{34}{Contrastive Predictive Coding}{equation.3.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Contrastive Predictive Coding for Computer Vision}{34}{subsection.3.3.2}\protected@file@percent }
\newlabel{subsec:unsupervised_cpc_for_vision}{{3.3.2}{34}{Contrastive Predictive Coding for Computer Vision}{subsection.3.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Multi-Directional Contrastive Predictive Coding}{34}{subsection.3.3.3}\protected@file@percent }
\newlabel{subsec:unsupervised_mdcpc}{{3.3.3}{34}{Multi-Directional Contrastive Predictive Coding}{subsection.3.3.3}{}}
\citation{oord2016pixel}
\citation{oord2016pixel}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Architecture of a Multi-Directional Masked Block\relax }}{35}{figure.caption.41}\protected@file@percent }
\newlabel{fig:multi-directional_masked_block}{{3.3}{35}{Architecture of a Multi-Directional Masked Block\relax }{figure.caption.41}{}}
\citation{veeling2018rotation}
\citation{veeling2018rotation}
\citation{litjens20181399}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Unsupervised Representation Learning Experiments}{36}{section.3.4}\protected@file@percent }
\newlabel{sec:unsupervised_experiments}{{3.4}{36}{Unsupervised Representation Learning Experiments}{section.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Dataset}{36}{subsection.3.4.1}\protected@file@percent }
\newlabel{subsec:unsupervised_dataset}{{3.4.1}{36}{Dataset}{subsection.3.4.1}{}}
\citation{veeling2018rotation,litjens20181399}
\citation{veeling2018rotation,litjens20181399}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Example images from the Patch Cameleyon dataset\nobreakspace  {}\citep  {veeling2018rotation,litjens20181399}.\relax }}{37}{figure.caption.42}\protected@file@percent }
\newlabel{fig:pcam_examples}{{3.4}{37}{Example images from the Patch Cameleyon dataset~\citep {veeling2018rotation,litjens20181399}.\relax }{figure.caption.42}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Experiment Setup}{37}{subsection.3.4.2}\protected@file@percent }
\newlabel{subsec:unsupervised_experiment}{{3.4.2}{37}{Experiment Setup}{subsection.3.4.2}{}}
\citation{xie2017aggregated}
\citation{kingma2014adam}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Training Parameters}{38}{subsection.3.4.3}\protected@file@percent }
\newlabel{subsec:unsupervised_training}{{3.4.3}{38}{Training Parameters}{subsection.3.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Results}{38}{subsection.3.4.4}\protected@file@percent }
\newlabel{subsec:unsupervised_results}{{3.4.4}{38}{Results}{subsection.3.4.4}{}}
\citation{oord2018representation}
\citation{krizhevsky2009learning}
\citation{deng2009imagenet}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Training loss each epoch with the CPC Models.\relax }}{39}{figure.caption.43}\protected@file@percent }
\newlabel{fig:cpc_training}{{3.5}{39}{Training loss each epoch with the CPC Models.\relax }{figure.caption.43}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Conclusion}{39}{section.3.5}\protected@file@percent }
\newlabel{sec:conclusion}{{3.5}{39}{Conclusion}{section.3.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Mean class testing accuracies of the CNN classifiers trained using varying amounts of training examples, with standard errors.\relax }}{40}{figure.caption.44}\protected@file@percent }
\newlabel{fig:cpc_cnn_results}{{3.6}{40}{Mean class testing accuracies of the CNN classifiers trained using varying amounts of training examples, with standard errors.\relax }{figure.caption.44}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Mean test accuracies of the CNN classifiers with different pre-training (standard deviation in parentheses).\relax }}{41}{table.caption.45}\protected@file@percent }
\newlabel{tab:cpc_cnn_results}{{3.1}{41}{Mean test accuracies of the CNN classifiers with different pre-training (standard deviation in parentheses).\relax }{table.caption.45}{}}
\citation{carse2022calibration}
\citation{maron2019systematic}
\citation{dai2020federated}
\citation{ulmer2020trust}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Predictive Probability Calibration}{42}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{ch:classification_claibration}{{4}{42}{Predictive Probability Calibration}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Introduction}{42}{section.4.1}\protected@file@percent }
\newlabel{sec:calibration_introduction}{{4.1}{42}{Introduction}{section.4.1}{}}
\citation{guo2017calibration}
\citation{mukhoti2020calibrating,frenkel2021network}
\citation{guo2017calibration}
\citation{muller2019does}
\citation{roelofs2022mitigating}
\citation{parzen1962estimation}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Measures of Calibration}{44}{section.4.2}\protected@file@percent }
\newlabel{sec:calibration_measures}{{4.2}{44}{Measures of Calibration}{section.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Example reliability diagram.\relax }}{44}{figure.caption.46}\protected@file@percent }
\newlabel{fig:reliability_diagram}{{4.1}{44}{Example reliability diagram.\relax }{figure.caption.46}{}}
\citation{gawlikowski2021survey}
\citation{hendrycks2019augmix}
\citation{hendrycks2018deep}
\citation{szegedy2016rethinking}
\citation{islam2021spatially}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Calibration Methods and Literature Review}{45}{section.4.3}\protected@file@percent }
\newlabel{sec:calibration_review}{{4.3}{45}{Calibration Methods and Literature Review}{section.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Model Regularisation For Calibration}{45}{subsection.4.3.1}\protected@file@percent }
\citation{lin2017focal}
\citation{mukhoti2020calibrating}
\citation{guo2017calibration,liang2020improved}
\citation{platt1999probabilistic}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Post-Hoc Calibration}{46}{subsection.4.3.2}\protected@file@percent }
\newlabel{eq:temperature_scaling}{{4.1}{46}{Post-Hoc Calibration}{equation.4.3.1}{}}
\citation{kwon2020uncertainty}
\citation{mackay1992bayesian,botev2017practical}
\citation{daxberger2021laplace}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Bayesian Approximation}{47}{subsection.4.3.3}\protected@file@percent }
\newlabel{subsec:bayesian_calibration}{{4.3.3}{47}{Bayesian Approximation}{subsection.4.3.3}{}}
\newlabel{eq:elbo}{{4.2}{47}{Bayesian Approximation}{equation.4.3.2}{}}
\citation{codella2018skin,combalia2019bcn20000,tschandl2018ham10000}
\citation{veeling2018rotation}
\citation{bejnordi2017diagnostic}
\citation{codella2018skin,combalia2019bcn20000,tschandl2018ham10000}
\citation{codella2018skin,combalia2019bcn20000,tschandl2018ham10000}
\citation{liu1989limited}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Calibration Experiments}{48}{section.4.4}\protected@file@percent }
\newlabel{sec:calibration_experiments}{{4.4}{48}{Calibration Experiments}{section.4.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Datasets}{48}{subsection.4.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Example images from the ISIC Challenge 2019 dataset\nobreakspace  {}\citep  {codella2018skin,combalia2019bcn20000,tschandl2018ham10000}.\relax }}{49}{figure.caption.47}\protected@file@percent }
\newlabel{fig:ISIC_examples}{{4.2}{49}{Example images from the ISIC Challenge 2019 dataset~\citep {codella2018skin,combalia2019bcn20000,tschandl2018ham10000}.\relax }{figure.caption.47}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Experiment Setup}{49}{subsection.4.4.2}\protected@file@percent }
\citation{tan2019efficient}
\citation{deng2009imagenet}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Training Parameters}{50}{subsection.4.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.4}Results}{50}{subsection.4.4.4}\protected@file@percent }
\newlabel{subsec:calibration_results}{{4.4.4}{50}{Results}{subsection.4.4.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Calibration and accuracy results for ISIC 2019 and PCam datasets. ISIC 2019 results are means and standard deviations over three iterations. Each section reports results from a single model type; TS denotes temperature scaling.\relax }}{51}{table.caption.48}\protected@file@percent }
\newlabel{tab:calibration_results}{{4.1}{51}{Calibration and accuracy results for ISIC 2019 and PCam datasets. ISIC 2019 results are means and standard deviations over three iterations. Each section reports results from a single model type; TS denotes temperature scaling.\relax }{table.caption.48}{}}
\citation{mukhoti2020calibrating}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Conclusion}{53}{section.4.5}\protected@file@percent }
\newlabel{sec:calibration_conclusion}{{4.5}{53}{Conclusion}{section.4.5}{}}
\citation{codella2018skin,combalia2019bcn20000,tschandl2018ham10000}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Asymmetrical Selective Classification}{54}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{ch:selective_classification}{{5}{54}{Asymmetrical Selective Classification}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Introduction}{54}{section.5.1}\protected@file@percent }
\newlabel{sec:selective_introduction}{{5.1}{54}{Introduction}{section.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Robust Selective Classification for Skin\\Lesions}{54}{subsection.5.1.1}\protected@file@percent }
\newlabel{subsec:robust and selective}{{5.1.1}{54}{Robust Selective Classification for Skin\\Lesions}{subsection.5.1.1}{}}
\citation{selective2019geifman}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Summary of Work}{55}{subsection.5.1.2}\protected@file@percent }
\newlabel{subsec:selective_summary_of_work}{{5.1.2}{55}{Summary of Work}{subsection.5.1.2}{}}
\citation{carse2021robust}
\citation{chow1957optimum}
\citation{el2010foundations}
\citation{hellman1970nearest,fumera2002support,wiener2015agnostic}
\citation{cortes2016learning}
\citation{geifman2017selective}
\citation{selective2019geifman}
\citation{gal2016dropout}
\citation{blundell2015weight}
\citation{mackay1992bayesian}
\citation{Gal2016Uncertainty}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Literature Review}{56}{section.5.2}\protected@file@percent }
\newlabel{sec:selective_review}{{5.2}{56}{Literature Review}{section.5.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Asymmetrical Selective Classification}{57}{section.5.3}\protected@file@percent }
\newlabel{sec:selective_classification}{{5.3}{57}{Asymmetrical Selective Classification}{section.5.3}{}}
\newlabel{fig:multiclasssymcosts}{{5.1a}{58}{\relax }{figure.caption.49}{}}
\newlabel{sub@fig:multiclasssymcosts}{{a}{58}{\relax }{figure.caption.49}{}}
\newlabel{fig:multiclassasymcosts}{{5.1b}{58}{\relax }{figure.caption.49}{}}
\newlabel{sub@fig:multiclassasymcosts}{{b}{58}{\relax }{figure.caption.49}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Visual representation of the cost matrices for the classes of the ISIC 2019 dataset. Panel (a) depicts a symmetrical cost matrix, in which the costs of misclassification are equivalent. Conversely, panel (b) illustrates an asymmetrical cost matrix, where the costs of misclassification are differentiated based on various factors.\relax }}{58}{figure.caption.49}\protected@file@percent }
\newlabel{fig:multiclasscosts}{{5.1}{58}{Visual representation of the cost matrices for the classes of the ISIC 2019 dataset. Panel (a) depicts a symmetrical cost matrix, in which the costs of misclassification are equivalent. Conversely, panel (b) illustrates an asymmetrical cost matrix, where the costs of misclassification are differentiated based on various factors.\relax }{figure.caption.49}{}}
\citation{gal2016dropout}
\newlabel{eq:expected_cost_multi}{{5.1}{59}{Asymmetrical Selective Classification}{equation.5.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Selective Classification Methods}{59}{section.5.4}\protected@file@percent }
\newlabel{sec:slective_classification_methods}{{5.4}{59}{Selective Classification Methods}{section.5.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Predictive Probabilities}{59}{subsection.5.4.1}\protected@file@percent }
\newlabel{subsec:selective_predictive_probabilites}{{5.4.1}{59}{Predictive Probabilities}{subsection.5.4.1}{}}
\newlabel{eq:softmax_response}{{5.2}{59}{Predictive Probabilities}{equation.5.4.2}{}}
\newlabel{eq:selective_temperature_scaling}{{5.3}{59}{Predictive Probabilities}{equation.5.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Bayesian Uncertainty}{59}{subsection.5.4.2}\protected@file@percent }
\newlabel{subsec:selective_uncertainity}{{5.4.2}{59}{Bayesian Uncertainty}{subsection.5.4.2}{}}
\citation{blundell2015weight}
\citation{mackay1992bayesian}
\citation{jospin2020hands}
\citation{freeman1965elementary}
\citation{shannon1948mathematical}
\citation{houlsby2011bayesian}
\citation{geifman2019selectivenet}
\newlabel{eq:avg_baysian_neural_network}{{5.4}{60}{Bayesian Uncertainty}{equation.5.4.4}{}}
\newlabel{eq:var_baysian_neural_network}{{5.5}{60}{Bayesian Uncertainty}{equation.5.4.5}{}}
\newlabel{eq:variation_ratio}{{5.6}{60}{Bayesian Uncertainty}{equation.5.4.6}{}}
\newlabel{eq:predictive_entropy}{{5.7}{60}{Bayesian Uncertainty}{equation.5.4.7}{}}
\newlabel{eq:mutual_information}{{5.8}{60}{Bayesian Uncertainty}{equation.5.4.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.3}SelectiveNet}{61}{subsection.5.4.3}\protected@file@percent }
\newlabel{subsec:selectivenet}{{5.4.3}{61}{SelectiveNet}{subsection.5.4.3}{}}
\newlabel{eq:selective_loss}{{5.9}{61}{SelectiveNet}{equation.5.4.9}{}}
\newlabel{eq:selectivenet_loss}{{5.10}{61}{SelectiveNet}{equation.5.4.10}{}}
\newlabel{eq:selectivenet}{{5.11}{61}{SelectiveNet}{equation.5.4.11}{}}
\citation{selective2019geifman}
\citation{codella2018skin,combalia2019bcn20000,tschandl2018ham10000}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.4}Expected Cost SelectiveNet}{62}{subsection.5.4.4}\protected@file@percent }
\newlabel{subsec:ec_selectivenet}{{5.4.4}{62}{Expected Cost SelectiveNet}{subsection.5.4.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Binary Experiments}{62}{section.5.5}\protected@file@percent }
\newlabel{sec:selective_binary_experiment}{{5.5}{62}{Binary Experiments}{section.5.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.1}Dataset Processing}{62}{subsection.5.5.1}\protected@file@percent }
\newlabel{subsec:selective_binary_dataset}{{5.5.1}{62}{Dataset Processing}{subsection.5.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Example images from the test data sets \(S_{in}\) and \(S_{unknown}\).\relax }}{63}{figure.caption.50}\protected@file@percent }
\newlabel{fig:isic_dataset_examples}{{5.2}{63}{Example images from the test data sets \(S_{in}\) and \(S_{unknown}\).\relax }{figure.caption.50}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.2}Experiment Setup}{63}{subsection.5.5.2}\protected@file@percent }
\citation{tan2019efficient}
\citation{gal2016dropout}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Binary experiments trained models and selection methods for each model to be evaluated.\relax }}{64}{table.caption.51}\protected@file@percent }
\newlabel{tab:binary-experiment-setup}{{5.1}{64}{Binary experiments trained models and selection methods for each model to be evaluated.\relax }{table.caption.51}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.3}Training Parameters}{64}{subsection.5.5.3}\protected@file@percent }
\newlabel{subsec:selective_binary_training}{{5.5.3}{64}{Training Parameters}{subsection.5.5.3}{}}
\citation{geifman2019selectivenet}
\citation{smith2017cyclical}
\citation{gal2016dropout}
\citation{geifman2019selectivenet}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.4}Results}{66}{subsection.5.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{SelectiveNet: Effect of Target Coverage}{66}{section*.52}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Does SelectiveNet Training Help?}{66}{section*.53}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{MC-Dropout, Temperature Scaling, and EC-SelectiveNet}{67}{section*.54}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Asymmetric Costs}{67}{section*.55}\protected@file@percent }
\citation{codella2018skin,combalia2019bcn20000,tschandl2018ham10000}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Multi class Experiments}{68}{section.5.6}\protected@file@percent }
\newlabel{sec:selective_multi_class_experiments}{{5.6}{68}{Multi class Experiments}{section.5.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.1}Dataset Processing}{68}{subsection.5.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.2}Experiment Setup}{68}{subsection.5.6.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Multi-class experiment trained models and selection methods to be evaluated.\relax }}{69}{table.caption.56}\protected@file@percent }
\newlabel{tab:multi-class-experiment-setup}{{5.2}{69}{Multi-class experiment trained models and selection methods to be evaluated.\relax }{table.caption.56}{}}
\citation{Blundell2015Weight}
\citation{Blundell2015Weight}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.3}Training Parameters}{70}{subsection.5.6.3}\protected@file@percent }
\newlabel{eq:scalemixture}{{5.12}{70}{Training Parameters}{equation.5.6.12}{}}
\newlabel{eq:elbo}{{5.13}{70}{Training Parameters}{equation.5.6.13}{}}
\citation{mackay1992bayesian}
\citation{botev2017practical}
\citation{kristiadi2020being}
\newlabel{eq:elbo_weighting}{{5.14}{71}{Training Parameters}{equation.5.6.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.4}Results}{71}{subsection.5.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{SelectiveNet, EC-SelectiveNet and Target Coverage}{71}{section*.57}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Effect of Temperature Scaling}{72}{section*.59}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Methods Bayesian Neural Networks}{72}{section*.61}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Results with experiments with SelectiveNet.\relax }}{73}{figure.caption.58}\protected@file@percent }
\newlabel{fig:multi-class-selective}{{5.3}{73}{Results with experiments with SelectiveNet.\relax }{figure.caption.58}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Results with experiments with temperature scaling.\relax }}{74}{figure.caption.60}\protected@file@percent }
\newlabel{fig:multi-class-temp}{{5.4}{74}{Results with experiments with temperature scaling.\relax }{figure.caption.60}{}}
\@writefile{toc}{\contentsline {subsubsection}{Measures of Uncertainty}{74}{section*.63}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Results with experiments with Bayesian Neural Networks.\relax }}{75}{figure.caption.62}\protected@file@percent }
\newlabel{fig:multi-class-bayesian}{{5.5}{75}{Results with experiments with Bayesian Neural Networks.\relax }{figure.caption.62}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Results with experiments with measures of uncertainty.\relax }}{76}{figure.caption.64}\protected@file@percent }
\newlabel{fig:multi-class-uncertainity}{{5.6}{76}{Results with experiments with measures of uncertainty.\relax }{figure.caption.64}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.7}Conclusion}{76}{section.5.7}\protected@file@percent }
\newlabel{sec:selective_conclusion}{{5.7}{76}{Conclusion}{section.5.7}{}}
\citation{du2020ai,wu2022skin}
\citation{tschandl2018ham10000,wen2021characteristics}
\citation{esteva2017dermatologist,haenssle2018man,han2018classification,tschandl2019expert}
\citation{fujisawa2019deep}
\citation{han2018classification}
\citation{glocker2022risk}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Evaluating Dataset Generalisation}{78}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{ch:dataset_generalisation}{{6}{78}{Evaluating Dataset Generalisation}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Introduction}{78}{section.6.1}\protected@file@percent }
\newlabel{sec:generalisation_intro}{{6.1}{78}{Introduction}{section.6.1}{}}
\citation{kelly2019key}
\citation{glocker2022risk}
\citation{prados2017spinal}
\citation{stacke2020measuring}
\citation{chin2022prepare}
\citation{weiss2016survey}
\citation{matsoukas2022makes}
\citation{deng2009imagenet}
\citation{matsoukas2022makes}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Example images from the Tayside and Forth Valley datasets.\relax }}{81}{figure.caption.65}\protected@file@percent }
\newlabel{fig:nhs_dataset_examples}{{6.1}{81}{Example images from the Tayside and Forth Valley datasets.\relax }{figure.caption.65}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Datasets}{81}{section.6.2}\protected@file@percent }
\newlabel{sec:generalisation_datasets}{{6.2}{81}{Datasets}{section.6.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Tayside Dataset}{81}{subsection.6.2.1}\protected@file@percent }
\newlabel{subsec:tayside_dataset}{{6.2.1}{81}{Tayside Dataset}{subsection.6.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}Forth Valley Dataset}{82}{subsection.6.2.2}\protected@file@percent }
\newlabel{subsec:forth_valley_dataset}{{6.2.2}{82}{Forth Valley Dataset}{subsection.6.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.3}Annotation Procedure}{82}{subsection.6.2.3}\protected@file@percent }
\newlabel{subsec:annotation_procedure}{{6.2.3}{82}{Annotation Procedure}{subsection.6.2.3}{}}
\citation{codella2018skin,combalia2019bcn20000,tschandl2018ham10000}
\citation{yang2019self}
\citation{yang2019self}
\citation{yang2019self}
\citation{tan2019efficient}
\citation{liu2021swin}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Generalisation Experiments}{84}{section.6.3}\protected@file@percent }
\newlabel{sec:generalisation_experiments}{{6.3}{84}{Generalisation Experiments}{section.6.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}Datasets}{84}{subsection.6.3.1}\protected@file@percent }
\newlabel{subsec:generalisation_datasets}{{6.3.1}{84}{Datasets}{subsection.6.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.2}Training Parameters}{84}{subsection.6.3.2}\protected@file@percent }
\newlabel{subsec:generalisation_training}{{6.3.2}{84}{Training Parameters}{subsection.6.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Example images from the SD-260 dataset\nobreakspace  {}\citep  {yang2019self}.\relax }}{85}{figure.caption.66}\protected@file@percent }
\newlabel{fig:sd260_examples}{{6.2}{85}{Example images from the SD-260 dataset~\citep {yang2019self}.\relax }{figure.caption.66}{}}
\citation{smith2017cyclical}
\@writefile{lot}{\contentsline {table}{\numberline {6.1}{\ignorespaces Number of images per diagnosis in each dataset.\relax }}{86}{table.caption.67}\protected@file@percent }
\newlabel{tab:generalisation_datasets}{{6.1}{86}{Number of images per diagnosis in each dataset.\relax }{table.caption.67}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.3}Experiment Setup}{86}{subsection.6.3.3}\protected@file@percent }
\newlabel{subsec:generalisation_experiment}{{6.3.3}{86}{Experiment Setup}{subsection.6.3.3}{}}
\citation{deng2009imagenet}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.4}Results}{87}{subsection.6.3.4}\protected@file@percent }
\newlabel{subsec:generalisation_results}{{6.3.4}{87}{Results}{subsection.6.3.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6.2}{\ignorespaces Class-balanced accuracy when training and testing on the various datasets.\relax }}{88}{table.caption.68}\protected@file@percent }
\newlabel{tab:generalisation_results}{{6.2}{88}{Class-balanced accuracy when training and testing on the various datasets.\relax }{table.caption.68}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6.3}{\ignorespaces Balanced class accuracy when CNN and SWIN transformers are tested on Tayside and Forth Valley data after various multi-dataset training sequences. \relax }}{89}{table.caption.69}\protected@file@percent }
\newlabel{tab:generalisation_models}{{6.3}{89}{Balanced class accuracy when CNN and SWIN transformers are tested on Tayside and Forth Valley data after various multi-dataset training sequences. \relax }{table.caption.69}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Balanced accuracy of models when tested on Tayside and Forth Valley datasets after various pre-training sequences. Bars are +/- one standard error computed from the variance over cross-validation folds.\relax }}{90}{figure.caption.70}\protected@file@percent }
\newlabel{fig:generalisation_models}{{6.3}{90}{Balanced accuracy of models when tested on Tayside and Forth Valley datasets after various pre-training sequences. Bars are +/- one standard error computed from the variance over cross-validation folds.\relax }{figure.caption.70}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Conclusion}{90}{section.6.4}\protected@file@percent }
\newlabel{sec:generalisation_conclusion}{{6.4}{90}{Conclusion}{section.6.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces Balanced accuracy of the models demonstrating the performance of dataset cross-generalisation between the Tayside and Forth Valley datasets.\relax }}{91}{figure.caption.71}\protected@file@percent }
\newlabel{fig:generalisation_testing}{{6.4}{91}{Balanced accuracy of the models demonstrating the performance of dataset cross-generalisation between the Tayside and Forth Valley datasets.\relax }{figure.caption.71}{}}
\citation{guan2021domain,carse2021robust}
\citation{carse2021robust,carse2022calibration}
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces ROC curves for CNNs and SWIN transformers pre-trained on SD-260 prior to training on either Tayside or Forth Valley data.\relax }}{94}{figure.caption.72}\protected@file@percent }
\newlabel{fig:generalisation_roc}{{6.5}{94}{ROC curves for CNNs and SWIN transformers pre-trained on SD-260 prior to training on either Tayside or Forth Valley data.\relax }{figure.caption.72}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusion and Discussion}{95}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{ch:conclusion_and_discussion}{{7}{95}{Conclusion and Discussion}{chapter.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Pathway to Complete System}{95}{section.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Summary of Contributions}{95}{section.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Limitations}{95}{section.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.4}Future Work}{95}{section.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.1}Active Learning}{95}{subsection.7.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.2}Unsupervised Learning}{95}{subsection.7.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.3}Selective Classification}{95}{subsection.7.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.4}Asymmetrical Risks}{96}{subsection.7.4.4}\protected@file@percent }
\bibdata{refs/intro,refs/active,refs/unsupervised,refs/calibration,refs/selective,refs/generalisation}
\bibcite{akrami2020brain}{{1}{2020}{{Akrami et~al.}}{{Akrami, Joshi, Li, Aydore \&\ Leahy}}}
\bibcite{arjovsky2017wasserstein}{{2}{2017}{{Arjovsky et~al.}}{{Arjovsky, Chintala \&\ Bottou}}}
\bibcite{bachman2019learning}{{3}{2019}{{Bachman et~al.}}{{Bachman, Hjelm \&\ Buchwalter}}}
\bibcite{bayramoglu2016transfer}{{4}{2016}{{Bayramoglu \&\ Heikkil{\"a}}}{{}}}
\bibcite{bejnordi2017diagnostic}{{5}{2017}{{Bejnordi et~al.}}{{Bejnordi, Veta, Van~Diest, Van~Ginneken, Karssemeijer, Litjens, Van Der~Laak, Hermsen, Manson, Balkenhol et~al.}}}
\bibcite{bengio2013representation}{{6}{2013}{{Bengio, Courville \&\ Vincent}}{{}}}
\bibcite{bengio2013generalized}{{7}{2013}{{Bengio, Yao, Alain \&\ Vincent}}{{}}}
\bibcite{blundell2015weight}{{8}{2015}{{Blundell et~al.}}{{Blundell, Cornebise, Kavukcuoglu \&\ Wierstra}}}
\@writefile{toc}{\contentsline {chapter}{References}{97}{subsection.7.4.4}\protected@file@percent }
\bibcite{botev2017practical}{{9}{2017}{{Botev et~al.}}{{Botev, Ritter \&\ Barber}}}
\bibcite{budd2021survey}{{10}{2021}{{Budd et~al.}}{{Budd, Robinson \&\ Kainz}}}
\bibcite{caron2018deep}{{11}{2018}{{Caron et~al.}}{{Caron, Bojanowski, Joulin \&\ Douze}}}
\bibcite{carse2022calibration}{{12}{2022}{{Carse et~al.}}{{Carse, Alvarez~Olmo \&\ McKenna}}}
\bibcite{carse2021unsupervised}{{13}{2021}{{Carse, Carey \&\ McKenna}}{{}}}
\bibcite{carse2019active}{{14}{2019}{{Carse \&\ McKenna}}{{}}}
\bibcite{carse2021robust}{{15}{2021}{{Carse, S{\"u}veges, Hogg, Trucco, Proby, Fleming \&\ McKenna}}{{}}}
\bibcite{chang2017unsupervised}{{16}{2017}{{Chang et~al.}}{{Chang, Han, Zhong, Snijders \&\ Mau}}}
\bibcite{chen2014cross}{{17}{2014}{{Chen et~al.}}{{Chen, Chen \&\ Hsu}}}
\bibcite{chin2022prepare}{{18}{2022}{{Chin et~al.}}{{Chin, Suveges, Carse, Butt, Muthiah, Morton, Trucco, Proby, McKenna \&\ Fleming}}}
\bibcite{chow1957optimum}{{19}{1957}{{Chow}}{{}}}
\bibcite{codella2018skin}{{20}{2018}{{Codella et~al.}}{{Codella, Gutman, Celebi, Helba, Marchetti, Dusza, Kalloo, Liopyris, Mishra, Kittler et~al.}}}
\bibcite{cohen2017emnist}{{21}{2017}{{Cohen et~al.}}{{Cohen, Afshar, Tapson \&\ Van~Schaik}}}
\bibcite{cohn1996active}{{22}{1996}{{Cohn et~al.}}{{Cohn, Ghahramani \&\ Jordan}}}
\bibcite{colling2020metabox}{{23}{2020}{{Colling et~al.}}{{Colling, Roese-Koerner, Gottschalk \&\ Rottmann}}}
\bibcite{combalia2019bcn20000}{{24}{2019}{{Combalia et~al.}}{{Combalia, Codella, Rotemberg, Helba, Vilaplana, Reiter, Carrera, Barreiro, Halpern, Puig et~al.}}}
\bibcite{cordts2016cityscapes}{{25}{2016}{{Cordts et~al.}}{{Cordts, Omran, Ramos, Rehfeld, Enzweiler, Benenson, Franke, Roth \&\ Schiele}}}
\bibcite{cortes2016learning}{{26}{2016}{{Cortes et~al.}}{{Cortes, DeSalvo \&\ Mohri}}}
\bibcite{dai2020federated}{{27}{2020}{{Dai et~al.}}{{Dai, Low \&\ Jaillet}}}
\bibcite{darlow2018cinic}{{28}{2018}{{Darlow et~al.}}{{Darlow, Crowley, Antoniou \&\ Storkey}}}
\bibcite{daxberger2021laplace}{{29}{2021}{{Daxberger et~al.}}{{Daxberger, Kristiadi, Immer, Eschenhagen, Bauer \&\ Hennig}}}
\bibcite{demir2015novel}{{30}{2015}{{Demir \&\ Bruzzone}}{{}}}
\bibcite{deng2009imagenet}{{31}{2009}{{Deng et~al.}}{{Deng, Dong, Socher, Li, Li \&\ Fei-Fei}}}
\bibcite{donahue2016adversarial}{{32}{2016}{{Donahue et~al.}}{{Donahue, Kr{\"a}henb{\"u}hl \&\ Darrell}}}
\bibcite{donahue2019large}{{33}{2019}{{Donahue \&\ Simonyan}}{{}}}
\bibcite{du2020ai}{{34}{2020}{{Du-Harpur et~al.}}{{Du-Harpur, Watt, Luscombe \&\ Lynch}}}
\bibcite{ducoffe2018adversarial}{{35}{2018}{{Ducoffe \&\ Precioso}}{{}}}
\bibcite{el2010foundations}{{36}{2010}{{El-Yaniv et~al.}}{{}}}
\bibcite{esteva2017dermatologist}{{37}{2017}{{Esteva et~al.}}{{Esteva, Kuprel, Novoa, Ko, Swetter, Blau \&\ Thrun}}}
\bibcite{farahani2009facility}{{38}{2009}{{Farahani \&\ Hekmatfar}}{{}}}
\bibcite{folmsbee2021whole}{{39}{2021}{{Folmsbee et~al.}}{{Folmsbee, Brandwein-Weber \&\ Doyle}}}
\bibcite{freeman1965elementary}{{40}{1965}{{Freeman}}{{}}}
\bibcite{frenkel2021network}{{41}{2021}{{Frenkel \&\ Goldberger}}{{}}}
\bibcite{fujisawa2019deep}{{42}{2019}{{Fujisawa et~al.}}{{Fujisawa, Otomo, Ogata, Nakamura, Fujita, Ishitsuka, Watanabe, Okiyama, Ohara \&\ Fujimoto}}}
\bibcite{fumera2002support}{{43}{2002}{{Fumera \&\ Roli}}{{}}}
\bibcite{Gal2016Uncertainty}{{44}{2016}{{Gal}}{{}}}
\bibcite{gal2016dropout}{{45}{2016}{{Gal \&\ Ghahramani}}{{}}}
\bibcite{gal2017deep}{{46}{2017}{{Gal et~al.}}{{Gal, Islam \&\ Ghahramani}}}
\bibcite{gamper2019pannuke}{{47}{2019}{{Gamper et~al.}}{{Gamper, Alemi~Koohbanani, Benet, Khuram \&\ Rajpoot}}}
\bibcite{gamper2020pannuke}{{48}{2020}{{Gamper et~al.}}{{Gamper, Koohbanani, Benes, Graham, Jahanifar, Khurram, Azam, Hewitt \&\ Rajpoot}}}
\bibcite{gawlikowski2021survey}{{49}{2021}{{Gawlikowski et~al.}}{{Gawlikowski, Tassi, Ali, Lee, Humt, Feng, Kruspe, Triebel, Jung, Roscher et~al.}}}
\bibcite{geifman2017selective}{{50}{2017}{{Geifman \&\ El-Yaniv}}{{}}}
\bibcite{selective2019geifman}{{51}{2019{\em  a}}{{Geifman \&\ El-Yaniv}}{{}}}
\bibcite{geifman2019selectivenet}{{52}{2019{\em  b}}{{Geifman \&\ El-Yaniv}}{{}}}
\bibcite{gidaris2018unsupervised}{{53}{2018}{{Gidaris et~al.}}{{Gidaris, Singh \&\ Komodakis}}}
\bibcite{glocker2022risk}{{54}{2022}{{Glocker et~al.}}{{Glocker, Jones, Bernhardt \&\ Winzeck}}}
\bibcite{glorot2010understanding}{{55}{2010}{{Glorot \&\ Bengio}}{{}}}
\bibcite{goodfellow2016deep}{{56}{2016}{{Goodfellow et~al.}}{{Goodfellow, Bengio \&\ Courville}}}
\bibcite{goodfellow2014advances}{{57}{2014}{{Goodfellow et~al.}}{{Goodfellow, Pouget-Abadie, Mirza, Xu, Warde-Farley, Ozair, Courville \&\ Bengio}}}
\bibcite{gorriz2017cost}{{58}{2017}{{Gorriz et~al.}}{{Gorriz, Carlier, Faure \&\ Giro-i Nieto}}}
\bibcite{guan2021domain}{{59}{2021}{{Guan \&\ Liu}}{{}}}
\bibcite{gulrajani2017improved}{{60}{2017}{{Gulrajani et~al.}}{{Gulrajani, Ahmed, Arjovsky, Dumoulin \&\ Courville}}}
\bibcite{guo2017calibration}{{61}{2017}{{Guo et~al.}}{{Guo, Pleiss, Sun \&\ Weinberger}}}
\bibcite{gutman2016skin}{{62}{2016}{{Gutman et~al.}}{{Gutman, Codella, Celebi, Helba, Marchetti, Mishra \&\ Halpern}}}
\bibcite{gutmann2010noise}{{63}{2010}{{Gutmann \&\ Hyv{\"a}rinen}}{{}}}
\bibcite{haenssle2018man}{{64}{2018}{{Haenssle et~al.}}{{Haenssle, Fink, Schneiderbauer, Toberer, Buhl, Blum, Kalloo, Hassen, Thomas, Enk et~al.}}}
\bibcite{han2018classification}{{65}{2018}{{Han et~al.}}{{Han, Kim, Lim, Park, Park \&\ Chang}}}
\bibcite{he2020momentum}{{66}{2020}{{He et~al.}}{{He, Fan, Wu, Xie \&\ Girshick}}}
\bibcite{he2016deep}{{67}{2016}{{He et~al.}}{{He, Zhang, Ren \&\ Sun}}}
\bibcite{hellman1970nearest}{{68}{1970}{{Hellman}}{{}}}
\bibcite{henaff2019data}{{69}{2019}{{H\'enaff et~al.}}{{H\'enaff, Srinivas, Fauw, Razavi, Doersch, Eslami \&\ van~den Oord}}}
\bibcite{hendrycks2018deep}{{70}{2018}{{Hendrycks et~al.}}{{Hendrycks, Mazeika \&\ Dietterich}}}
\bibcite{hendrycks2019augmix}{{71}{2019}{{Hendrycks et~al.}}{{Hendrycks, Mu, Cubuk, Zoph, Gilmer \&\ Lakshminarayanan}}}
\bibcite{hjelm2018learning}{{72}{2018}{{Hjelm et~al.}}{{Hjelm, Fedorov, Lavoie-Marchildon, Grewal, Bachman, Trischler \&\ Bengio}}}
\bibcite{hou2016automatic}{{73}{2016}{{Hou et~al.}}{{Hou, Singh, Samaras, Kurc, Gao, Seidman \&\ Saltz}}}
\bibcite{houlsby2011bayesian}{{74}{2011}{{Houlsby et~al.}}{{Houlsby, Husz{\'a}r, Ghahramani \&\ Lengyel}}}
\bibcite{hu2018unsupervised}{{75}{2018}{{Hu et~al.}}{{Hu, Tang, Chang, Fan, Lai \&\ Xu}}}
\bibcite{islam2021spatially}{{76}{2021}{{Islam \&\ Glocker}}{{}}}
\bibcite{jin2021reducing}{{77}{2021}{{Jin et~al.}}{{Jin, An, Wang, Wen \&\ Wu}}}
\bibcite{jospin2020hands}{{78}{2020}{{Jospin et~al.}}{{Jospin, Buntine, Boussaid, Laga \&\ Bennamoun}}}
\bibcite{kaji2019overview}{{79}{2019}{{Kaji \&\ Kida}}{{}}}
\bibcite{kampffmeyer2016semantic}{{80}{2016}{{Kampffmeyer et~al.}}{{Kampffmeyer, Salberg \&\ Jenssen}}}
\bibcite{kelly2019key}{{81}{2019}{{Kelly et~al.}}{{Kelly, Karthikesalingam, Suleyman, Corrado \&\ King}}}
\bibcite{kingma2014adam}{{82}{2014}{{Kingma \&\ Ba}}{{}}}
\bibcite{kingma2013auto}{{83}{2013}{{Kingma \&\ Welling}}{{}}}
\bibcite{kirsch2019batchbald}{{84}{2019}{{Kirsch et~al.}}{{Kirsch, Van~Amersfoort \&\ Gal}}}
\bibcite{konyushkova2019geometry}{{85}{2019}{{Konyushkova et~al.}}{{Konyushkova, Sznitman \&\ Fua}}}
\bibcite{kramer1991nonlinear}{{86}{1991}{{Kramer}}{{}}}
\bibcite{kristiadi2020being}{{87}{2020}{{Kristiadi et~al.}}{{Kristiadi, Hein \&\ Hennig}}}
\bibcite{krizhevsky2009learning}{{88}{2009}{{Krizhevsky \&\ Hinton}}{{}}}
\bibcite{kullback1951information}{{89}{1951}{{Kullback \&\ Leibler}}{{}}}
\bibcite{kurakin2016adversarial}{{90}{2016}{{Kurakin et~al.}}{{Kurakin, Goodfellow \&\ Bengio}}}
\bibcite{kwon2020uncertainty}{{91}{2020}{{Kwon et~al.}}{{Kwon, Won, Kim \&\ Paik}}}
\bibcite{lake2015human}{{92}{2015}{{Lake et~al.}}{{Lake, Salakhutdinov \&\ Tenenbaum}}}
\bibcite{lecun1998gradient}{{93}{1998}{{LeCun et~al.}}{{LeCun, Bottou, Bengio \&\ Haffner}}}
\bibcite{lee2013pseudo}{{94}{2013}{{Lee}}{{}}}
\bibcite{lewis1995sequential}{{95}{1995}{{Lewis}}{{}}}
\bibcite{liang2020improved}{{96}{2020}{{Liang et~al.}}{{Liang, Zhang, Wang \&\ Jacobs}}}
\bibcite{lin2017focal}{{97}{2017}{{Lin et~al.}}{{Lin, Goyal, Girshick, He \&\ Doll{\'a}r}}}
\bibcite{litjens20181399}{{98}{2018}{{Litjens et~al.}}{{Litjens, Bandi, Bejnordi, Geessink, Balkenhol, Bult, Halilovic, Hermsen, van~de Loo, Vogels, Manson, Stathonikos, Baidoshvili, van Diest, Wauters, van Dijk \&\ van~der Laak}}}
\bibcite{litjens2017survey}{{99}{2017}{{Litjens et~al.}}{{Litjens, Kooi, Bejnordi, Setio, Ciompi, Ghafoorian, Van Der~Laak, Van~Ginneken \&\ S{\'a}nchez}}}
\bibcite{liu1989limited}{{100}{1989}{{Liu \&\ Nocedal}}{{}}}
\bibcite{liu2020semi}{{101}{2020}{{Liu et~al.}}{{Liu, Lei, Wan, Liu, Luo \&\ Feng}}}
\bibcite{liu2021swin}{{102}{2021}{{Liu et~al.}}{{Liu, Lin, Cao, Hu, Wei, Zhang, Lin \&\ Guo}}}
\bibcite{mackay1992bayesian}{{103}{1992}{{MacKay}}{{}}}
\bibcite{mackowiak2018cereals}{{104}{2018}{{Mackowiak et~al.}}{{Mackowiak, Lenz, Ghori, Diego, Lange \&\ Rother}}}
\bibcite{madabhushi2016image}{{105}{2016}{{Madabhushi \&\ Lee}}{{}}}
\bibcite{makhzani2013k}{{106}{2013}{{Makhzani \&\ Frey}}{{}}}
\bibcite{maron2019systematic}{{107}{2019}{{Maron et~al.}}{{Maron, Weichenthal, Utikal, Hekler, Berking, Hauschild, Enk, Haferkamp, Klode, Schadendorf et~al.}}}
\bibcite{matsoukas2022makes}{{108}{2022}{{Matsoukas et~al.}}{{Matsoukas, Haslum, Sorkhei, S{\"o}derberg \&\ Smith}}}
\bibcite{misra2020self}{{109}{2020}{{Misra \&\ Maaten}}{{}}}
\bibcite{mukherjee2019clustergan}{{110}{2019}{{Mukherjee et~al.}}{{Mukherjee, Asnani, Lin \&\ Kannan}}}
\bibcite{mukhoti2020calibrating}{{111}{2020}{{Mukhoti et~al.}}{{Mukhoti, Kulharia, Sanyal, Golodetz, Torr \&\ Dokania}}}
\bibcite{muller2019does}{{112}{2019}{{M{\"u}ller et~al.}}{{M{\"u}ller, Kornblith \&\ Hinton}}}
\bibcite{noroozi2016unsupervised}{{113}{2016}{{Noroozi \&\ Favaro}}{{}}}
\bibcite{parikh2014proximal}{{114}{2014}{{Parikh et~al.}}{{Parikh, Boyd et~al.}}}
\bibcite{parzen1962estimation}{{115}{1962}{{Parzen}}{{}}}
\bibcite{platt1999probabilistic}{{116}{1999}{{Platt et~al.}}{{}}}
\bibcite{pop2018deep}{{117}{2018}{{Pop \&\ Fulop}}{{}}}
\bibcite{prados2017spinal}{{118}{2017}{{Prados et~al.}}{{Prados, Ashburner, Blaiotta, Brosch, Carballido-Gamio, Cardoso, Conrad, Datta, D{\'a}vid, De~Leener et~al.}}}
\bibcite{prechelt1998early}{{119}{1998}{{Prechelt}}{{}}}
\bibcite{rasmus2015semi}{{120}{2015}{{Rasmus et~al.}}{{Rasmus, Berglund, Honkala, Valpola \&\ Raiko}}}
\bibcite{ren2021survey}{{121}{2021}{{Ren et~al.}}{{Ren, Xiao, Chang, Huang, Li, Gupta, Chen \&\ Wang}}}
\bibcite{roelofs2022mitigating}{{122}{2022}{{Roelofs et~al.}}{{Roelofs, Cain, Shlens \&\ Mozer}}}
\bibcite{roy2001toward}{{123}{2001}{{Roy \&\ McCallum}}{{}}}
\bibcite{sener2017active}{{124}{2017}{{Sener \&\ Savarese}}{{}}}
\bibcite{settles2012active}{{125}{2012}{{Settles}}{{}}}
\bibcite{settles2008analysis}{{126}{2008}{{Settles \&\ Craven}}{{}}}
\bibcite{settles2008active2}{{127}{2008}{{Settles et~al.}}{{Settles, Craven \&\ Friedland}}}
\bibcite{settles2007multiple}{{128}{2007}{{Settles et~al.}}{{Settles, Craven \&\ Ray}}}
\bibcite{seung1992query}{{129}{1992}{{Seung et~al.}}{{Seung, Opper \&\ Sompolinsky}}}
\bibcite{shannon1948mathematical}{{130}{1948}{{Shannon}}{{}}}
\bibcite{shao2018deep}{{131}{2018}{{Shao et~al.}}{{Shao, Sun \&\ Zhang}}}
\bibcite{shi2019active}{{132}{2019}{{Shi et~al.}}{{Shi, Dou, Xue, Qin, Chen \&\ Heng}}}
\bibcite{shin1949mathematical}{{133}{1949}{{Shin \&\ Kim}}{{}}}
\bibcite{shurrab2022self}{{134}{2022}{{Shurrab \&\ Duwairi}}{{}}}
\bibcite{sirinukunwattana2016locality}{{135}{2016}{{Sirinukunwattana et~al.}}{{Sirinukunwattana, Raza, Tsang, Snead, Cree \&\ Rajpoot}}}
\bibcite{smith2017cyclical}{{136}{2017}{{Smith}}{{}}}
\bibcite{srinidhi2020deep}{{137}{2020}{{Srinidhi et~al.}}{{Srinidhi, Ciga \&\ Martel}}}
\bibcite{srivastav2021improved}{{138}{2021}{{Srivastav et~al.}}{{Srivastav, Bajpai \&\ Srivastava}}}
\bibcite{srivastava2014dropout}{{139}{2014}{{Srivastava et~al.}}{{Srivastava, Hinton, Krizhevsky, Sutskever \&\ Salakhutdinov}}}
\bibcite{stacke2020measuring}{{140}{2020}{{Stacke et~al.}}{{Stacke, Eilertsen, Unger \&\ Lundstr{\"o}m}}}
\bibcite{szegedy2016rethinking}{{141}{2016}{{Szegedy et~al.}}{{Szegedy, Vanhoucke, Ioffe, Shlens \&\ Wojna}}}
\bibcite{tan2019efficient}{{142}{2019}{{Tan \&\ Le}}{{}}}
\bibcite{thiagarajan2020improving}{{143}{2020}{{Thiagarajan et~al.}}{{Thiagarajan, Venkatesh, Rajan \&\ Sattigeri}}}
\bibcite{tizhoosh2018artificial}{{144}{2018}{{Tizhoosh \&\ Pantanowitz}}{{}}}
\bibcite{tschandl2019expert}{{145}{2019}{{Tschandl et~al.}}{{Tschandl, Rosendahl, Akay, Argenziano, Blum, Braun, Cabo, Gourhant, Kreusch, Lallas et~al.}}}
\bibcite{tschandl2018ham10000}{{146}{2018}{{Tschandl et~al.}}{{Tschandl, Rosendahl \&\ Kittler}}}
\bibcite{ulmer2020trust}{{147}{2020}{{Ulmer et~al.}}{{Ulmer, Meijerink \&\ Cin{\`a}}}}
\bibcite{oord2016pixel}{{148}{2016}{{van~den Oord et~al.}}{{van~den Oord, Kalchbrenner \&\ Kavukcuoglu}}}
\bibcite{oord2018representation}{{149}{2018}{{van~den Oord et~al.}}{{van~den Oord, Li \&\ Vinyals}}}
\bibcite{veeling2018rotation}{{150}{2018}{{Veeling et~al.}}{{Veeling, Linmans, Winkens, Cohen \&\ Welling}}}
\bibcite{wang2017cost}{{151}{2017}{{Wang et~al.}}{{Wang, Zhang, Li, Zhang \&\ Lin}}}
\bibcite{wei2020recent}{{152}{2020}{{Wei \&\ Mahmood}}{{}}}
\bibcite{weiss2016survey}{{153}{2016}{{Weiss et~al.}}{{Weiss, Khoshgoftaar \&\ Wang}}}
\bibcite{wen2021characteristics}{{154}{2021}{{Wen et~al.}}{{Wen, Khan, Xu, Ibrahim, Smith, Caballero, Zepeda, de~Blas~Perez, Denniston, Liu et~al.}}}
\bibcite{wiener2015agnostic}{{155}{2015}{{Wiener \&\ El-Yaniv}}{{}}}
\bibcite{wu2022skin}{{156}{2022}{{Wu et~al.}}{{Wu, Chen, Zeng, Pan, Wang \&\ Zhao}}}
\bibcite{wu2018unsupervised}{{157}{2018}{{Wu et~al.}}{{Wu, Xiong, Yu \&\ Lin}}}
\bibcite{xie2017aggregated}{{158}{2017}{{Xie et~al.}}{{Xie, Girshick, Doll{\'a}r, Tu \&\ He}}}
\bibcite{yang2019self}{{159}{2019}{{Yang et~al.}}{{Yang, Wu, Liang, Sun, Cheng, Rosin \&\ Wang}}}
\bibcite{yi2019generative}{{160}{2019}{{Yi et~al.}}{{Yi, Walia \&\ Babyn}}}
\bibcite{zeiler2012adadelta}{{161}{2012}{{Zeiler}}{{}}}
\bibcite{zhao2019data}{{162}{2019}{{Zhao et~al.}}{{Zhao, Balakrishnan, Durand, Guttag \&\ Dalca}}}
\bibcite{zhdanov2019diverse}{{163}{2019}{{Zhdanov}}{{}}}
\bibcite{zhou2021preservational}{{164}{2021}{{Zhou et~al.}}{{Zhou, Lu, Yang, Han \&\ Yu}}}
\bibcite{zhuang2019local}{{165}{2019}{{Zhuang et~al.}}{{Zhuang, Zhai \&\ Yamins}}}
\@writefile{toc}{\contentsline {chapter}{Appendices}{114}{section*.74}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {A}List of Publications and Achievements}{115}{appendix.a.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{app:list_of_publications}{{A}{115}{List of Publications and Achievements}{appendix.a.A}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}First Authored Publications}{115}{section.a.A.1}\protected@file@percent }
\newlabel{sec:first_authored_publications}{{A.1}{115}{First Authored Publications}{section.a.A.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.2}Contributed Publications}{116}{section.a.A.2}\protected@file@percent }
\newlabel{sec:contributed_publications}{{A.2}{116}{Contributed Publications}{section.a.A.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.3}Awards}{116}{section.a.A.3}\protected@file@percent }
\newlabel{sec:awards}{{A.3}{116}{Awards}{section.a.A.3}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Selective Classification Results}{117}{appendix.a.B}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{app:selective_classification_results}{{B}{117}{Selective Classification Results}{appendix.a.B}{}}
\gdef \@abspage@last{131}
