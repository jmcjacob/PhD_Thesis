\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Pool-based active learning framework.\relax }}{6}{figure.caption.16}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Three example regions from the CRCHistoPhenotypes dataset\nobreakspace {}\cite {sirinukunwattana2016locality} with multiple nuclei that will be extracted into patches and augmented.\relax }}{11}{figure.caption.20}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Average test accuracy of trained models with different amounts of annotated regions selected with query strategises.\relax }}{14}{figure.caption.23}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Average test mean class accuracy of trained models with different amounts of annotated regions selected with query strategises.\relax }}{14}{figure.caption.24}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces Average test loss of trained models with different amounts of annotated regions selected with query strategises.\relax }}{15}{figure.caption.25}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces (a) An example image from the ImageNet dataset\nobreakspace {}\cite {deng2009imagenet}. (b) Extracted overlapping patches with those used to produce context and autoregressor direction highlighted. (c) An example image from the Patch Camelyon dataset\nobreakspace {}\cite {veeling2018rotation}. (d) Extracted overlapping patches with those used to produce context and autoregressor direction highlighted.\relax }}{17}{figure.caption.26}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Proposed active learning framework with learnt representations from unsupervised representation learning on unannotated data.\relax }}{19}{figure.caption.27}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces Architecture of a Multi-Directional Masked Block\relax }}{22}{figure.caption.28}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Example Images from the ISIC Challenge 2019 dataset.\relax }}{32}{figure.caption.30}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Cost matrices for the classes of the ISIC 2019 dataset. (a) Shows a symmetrical cost matrices where all costs of misclassification are equal. (b) shows a asymmetrical cost matrix where mis-classifications have different costs based on numerous factors.\relax }}{40}{figure.caption.32}%
\contentsline {figure}{\numberline {5.2}{\ignorespaces Example images from the test data sets \(S_{in}\) and \(S_{unknown}\).\relax }}{44}{figure.caption.33}%
\contentsline {figure}{\numberline {5.3}{\ignorespaces Cost-coverage curves for SelectiveNets trained with different target coverages. From left to right: \(S_{in}\), \(S_{unknown}\) and \(S_{combined}\).\relax }}{45}{figure.caption.35}%
\contentsline {figure}{\numberline {5.4}{\ignorespaces Cost-coverage curves using MC-Dropout on $S_{in}$, $S_{unknown}$, and $S_{combined}$\relax }}{46}{figure.caption.38}%
\contentsline {figure}{\numberline {5.5}{\ignorespaces Cost-coverage curves. From left to right: \(S_{in}\), \(S_{unknown}\) and \(S_{combined}\).\relax }}{47}{figure.caption.39}%
\contentsline {figure}{\numberline {5.6}{\ignorespaces Cost-coverage curves for SelectiveNet and EC-SelectiveNet. From left to right: $C_{1,0}=1$ (symmetric costs), $10$, and $50$ (highly asymmetric costs)\relax }}{47}{figure.caption.41}%
\contentsline {figure}{\numberline {5.7}{\ignorespaces Cost-coverage curves for cross-entropy training and EC-SelectiveNet combined with temperature scaling. From left to right: $C_{1,0}=1$ (symmetric costs), $10$, and $50$ (highly asymmetric costs)\relax }}{48}{figure.caption.42}%
\addvspace {10\p@ }
\addvspace {10\p@ }
