\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Pool-based active learning framework.\relax }}{7}{figure.caption.17}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces A visual illustration of the core-sets query strategy, in which four points are selected that cover all other data points and minimize $\delta _s$\nobreakspace {}\citep {sener2017active}.\relax }}{12}{figure.caption.22}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Three example regions from the CRCHistoPhenotypes dataset\nobreakspace {}\cite {sirinukunwattana2016locality} are shown, each containing multiple nuclei that will be extracted into patches and augmented.\relax }}{17}{figure.caption.24}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Average test accuracy of trained models using different amounts of annotated regions selected through various query strategies.\relax }}{20}{figure.caption.27}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces Average test mean class accuracy of trained models using different amounts of annotated regions selected through various query strategies.\relax }}{21}{figure.caption.28}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces Average test loss of trained models using different amounts of annotated regions selected through various query strategies.\relax }}{21}{figure.caption.29}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces (a) An example image from the ImageNet dataset\nobreakspace {}\citep {deng2009imagenet}. (b) Extracted overlapping patches with those used to produce context and autoregressor direction highlighted. (c) An example image from the Patch Camelyon dataset\nobreakspace {}\citep {veeling2018rotation}. (d) Extracted overlapping patches with those used to produce context and autoregressor direction highlighted.\relax }}{24}{figure.caption.30}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Proposed active learning framework with learnt representations from unsupervised representation learning on unannotated data.\relax }}{25}{figure.caption.31}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces Architecture of a Multi-Directional Masked Block\relax }}{35}{figure.caption.41}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces Example images from the Patch Cameleyon dataset\nobreakspace {}\citep {veeling2018rotation,litjens20181399}.\relax }}{37}{figure.caption.42}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces Training loss each epoch with the CPC Models.\relax }}{39}{figure.caption.43}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces Mean class testing accuracies of the CNN classifiers trained using varying amounts of training examples, with standard errors.\relax }}{40}{figure.caption.44}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Example reliability diagram.\relax }}{44}{figure.caption.46}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces Example images from the ISIC Challenge 2019 dataset\nobreakspace {}\citep {codella2018skin,combalia2019bcn20000,tschandl2018ham10000}.\relax }}{49}{figure.caption.47}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Visual representation of the cost matrices for the classes of the ISIC 2019 dataset. Panel (a) depicts a symmetrical cost matrix, in which the costs of misclassification are equivalent. Conversely, panel (b) illustrates an asymmetrical cost matrix, where the costs of misclassification are differentiated based on various factors.\relax }}{57}{figure.caption.49}%
\contentsline {figure}{\numberline {5.2}{\ignorespaces Example images from the test data sets \(S_{in}\) and \(S_{unknown}\).\relax }}{62}{figure.caption.50}%
\contentsline {figure}{\numberline {5.3}{\ignorespaces Results with experiments with Bayesian Neural Networks.\relax }}{71}{figure.caption.57}%
\contentsline {figure}{\numberline {5.4}{\ignorespaces Results with experiments with measures of uncertainty.\relax }}{72}{figure.caption.58}%
\contentsline {figure}{\numberline {5.5}{\ignorespaces Results with experiments with SelectiveNet.\relax }}{73}{figure.caption.59}%
\contentsline {figure}{\numberline {5.6}{\ignorespaces Results with experiments with temperature scaling.\relax }}{74}{figure.caption.60}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {6.1}{\ignorespaces Example images from the Tayside and Forth Valley datasets.\relax }}{78}{figure.caption.61}%
\contentsline {figure}{\numberline {6.2}{\ignorespaces Example images from the SD-260 dataset\nobreakspace {}\citep {yang2019self}.\relax }}{82}{figure.caption.62}%
\contentsline {figure}{\numberline {6.3}{\ignorespaces Balanced accuracy of models when tested on Tayside and Forth Valley datasets after various pre-training sequences. Bars are +/- one standard error computed from the variance over cross-validation folds.\relax }}{87}{figure.caption.66}%
\contentsline {figure}{\numberline {6.4}{\ignorespaces Balanced accuracy of the models demonstrating the performance of dataset cross-generalisation between the Tayside and Forth Valley datasets.\relax }}{88}{figure.caption.67}%
\contentsline {figure}{\numberline {6.5}{\ignorespaces ROC curves for CNNs and SWIN transformers pre-trained on SD-260 prior to training on either Tayside or Forth Valley data.\relax }}{91}{figure.caption.68}%
\addvspace {10\p@ }
\addvspace {10\p@ }
