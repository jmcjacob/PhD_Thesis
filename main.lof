\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Pool-based active learning framework.\relax }}{7}{figure.caption.17}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces A visual illustration of the core-sets query strategy, in which four points are selected that cover all other data points and minimize $\delta _s$\nobreakspace {}\citep {sener2017active}.\relax }}{12}{figure.caption.22}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Three example regions from the CRCHistoPhenotypes dataset\nobreakspace {}\cite {sirinukunwattana2016locality} are shown, each containing multiple nuclei that will be extracted into patches and augmented.\relax }}{17}{figure.caption.24}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Average test accuracy of trained models using different amounts of annotated regions selected through various query strategies.\relax }}{20}{figure.caption.27}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces Average test mean class accuracy of trained models using different amounts of annotated regions selected through various query strategies.\relax }}{21}{figure.caption.28}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces Average test loss of trained models using different amounts of annotated regions selected through various query strategies.\relax }}{21}{figure.caption.29}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces (a) An example image from the ImageNet dataset\nobreakspace {}\citep {deng2009imagenet}. (b) Extracted overlapping patches with those used to produce context and autoregressor direction highlighted. (c) An example image from the Patch Camelyon dataset\nobreakspace {}\citep {veeling2018rotation}. (d) Extracted overlapping patches with those used to produce context and autoregressor direction highlighted.\relax }}{24}{figure.caption.30}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Proposed active learning framework with learnt representations from unsupervised representation learning on unannotated data.\relax }}{25}{figure.caption.31}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces Architecture of a Multi-Directional Masked Block\relax }}{35}{figure.caption.41}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces Example images from the Patch Cameleyon dataset\nobreakspace {}\citep {veeling2018rotation,litjens20181399}.\relax }}{37}{figure.caption.42}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces Training loss each epoch with the CPC Models.\relax }}{39}{figure.caption.43}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces Mean class testing accuracies of the CNN classifiers trained using varying amounts of training examples, with standard errors.\relax }}{40}{figure.caption.44}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Example reliability diagram.\relax }}{44}{figure.caption.46}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces Example images from the ISIC Challenge 2019 dataset\nobreakspace {}\citep {codella2018skin,combalia2019bcn20000,tschandl2018ham10000}.\relax }}{49}{figure.caption.47}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Visual representation of the cost matrices for the classes of the ISIC 2019 dataset. Panel (a) depicts a symmetrical cost matrix, in which the costs of misclassification are equivalent. Conversely, panel (b) illustrates an asymmetrical cost matrix, where the costs of misclassification are differentiated based on various factors.\relax }}{58}{figure.caption.49}%
\contentsline {figure}{\numberline {5.2}{\ignorespaces Example images from the test data sets \(S_{in}\) and \(S_{unknown}\).\relax }}{63}{figure.caption.50}%
\contentsline {figure}{\numberline {5.3}{\ignorespaces Cost-coverage curves for SelectiveNets trained with different target coverages. From top to bottom: $S_{in}$, $S_{unknown}$ and $S_{combined}$.\relax }}{67}{figure.caption.53}%
\contentsline {figure}{\numberline {5.4}{\ignorespaces Cost-coverage curves using MC-Dropout. From top to bottom: $S_{in}$, $S_{unknown}$ and $S_{combined}$.\relax }}{68}{figure.caption.55}%
\contentsline {figure}{\numberline {5.5}{\ignorespaces Cost-coverage curves for different selective classification methods. From top to bottom: $S_{in}$, $S_{unknown}$ and $S_{combined}$.\relax }}{69}{figure.caption.57}%
\contentsline {figure}{\numberline {5.6}{\ignorespaces Cost-coverage curves for SelectiveNet and EC-SelectiveNet. From top to bottom: $C_{1,0}=1$, $C_{1,0}=10$ and $C_{1,0}=50$.\relax }}{70}{figure.caption.58}%
\contentsline {figure}{\numberline {5.7}{\ignorespaces Cost-coverage curves for cross-entropy training and EC-SelectiveNet combined with temperature scaling. From top to bottom: $C_{1,0}=1$, $C_{1,0}=10$ and $C_{1,0}=50$.\relax }}{71}{figure.caption.60}%
\contentsline {figure}{\numberline {5.8}{\ignorespaces Results with experiments with SelectiveNet.\relax }}{76}{figure.caption.63}%
\contentsline {figure}{\numberline {5.9}{\ignorespaces Results with experiments with temperature scaling.\relax }}{77}{figure.caption.65}%
\contentsline {figure}{\numberline {5.10}{\ignorespaces Results with experiments with Bayesian Neural Networks.\relax }}{78}{figure.caption.67}%
\contentsline {figure}{\numberline {5.11}{\ignorespaces Results with experiments with measures of uncertainty.\relax }}{79}{figure.caption.69}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {6.1}{\ignorespaces Example images from the Tayside and Forth Valley datasets.\relax }}{84}{figure.caption.70}%
\contentsline {figure}{\numberline {6.2}{\ignorespaces Example images from the SD-260 dataset\nobreakspace {}\citep {yang2019self}.\relax }}{88}{figure.caption.71}%
\contentsline {figure}{\numberline {6.3}{\ignorespaces Balanced accuracy of models when tested on Tayside and Forth Valley datasets after various pre-training sequences. Bars are +/- one standard error computed from the variance over cross-validation folds.\relax }}{93}{figure.caption.75}%
\contentsline {figure}{\numberline {6.4}{\ignorespaces Balanced accuracy of the models demonstrating the performance of dataset cross-generalisation between the Tayside and Forth Valley datasets.\relax }}{94}{figure.caption.76}%
\contentsline {figure}{\numberline {6.5}{\ignorespaces ROC curves for CNNs and SWIN transformers pre-trained on SD-260 prior to training on either Tayside or Forth Valley data.\relax }}{97}{figure.caption.77}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
