\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Pool-based active learning framework.\relax }}{7}{figure.caption.17}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces A visual illustration of the core-sets query strategy, in which four points are selected that cover all other data points and minimize $\delta _s$\nobreakspace {}\citep {sener2017active}.\relax }}{12}{figure.caption.22}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Three example regions from the CRCHistoPhenotypes dataset\nobreakspace {}\cite {sirinukunwattana2016locality} are shown, each containing multiple nuclei that will be extracted into patches and augmented.\relax }}{17}{figure.caption.24}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Average test accuracy of trained models using different amounts of annotated regions selected through various query strategies.\relax }}{20}{figure.caption.27}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces Average test mean class accuracy of trained models using different amounts of annotated regions selected through various query strategies.\relax }}{21}{figure.caption.28}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces Average test loss of trained models using different amounts of annotated regions selected through various query strategies.\relax }}{21}{figure.caption.29}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces (a) An example image from the ImageNet dataset\nobreakspace {}\citep {deng2009imagenet}. (b) Extracted overlapping patches with those used to produce context and autoregressor direction highlighted. (c) An example image from the Patch Camelyon dataset\nobreakspace {}\citep {veeling2018rotation}. (d) Extracted overlapping patches with those used to produce context and autoregressor direction highlighted.\relax }}{24}{figure.caption.30}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Proposed active learning framework with learnt representations from unsupervised representation learning on unannotated data.\relax }}{26}{figure.caption.31}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces Architecture of a Multi-Directional Masked Block\relax }}{28}{figure.caption.32}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces Training loss each epoch with the CPC Models.\relax }}{31}{figure.caption.33}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces Mean class testing accuracies of the CNN classifiers trained using varying amounts of training examples, with standard errors.\relax }}{32}{figure.caption.34}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Example reliability diagram.\relax }}{36}{figure.caption.36}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces Example images from the ISIC Challenge 2019 dataset\nobreakspace {}\citep {codella2018skin,combalia2019bcn20000,tschandl2018ham10000}.\relax }}{41}{figure.caption.37}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Cost matrices for the classes of the ISIC 2019 dataset. (a) Shows a symmetrical cost matrices where all costs of misclassification are equal. (b) shows a asymmetrical cost matrix where mis-classifications have different costs based on numerous factors.\relax }}{49}{figure.caption.39}%
\contentsline {figure}{\numberline {5.2}{\ignorespaces Example images from the test data sets \(S_{in}\) and \(S_{unknown}\).\relax }}{53}{figure.caption.40}%
\contentsline {figure}{\numberline {5.3}{\ignorespaces Cost-coverage curves for SelectiveNets trained with different target coverages. From left to right: \(S_{in}\), \(S_{unknown}\) and \(S_{combined}\).\relax }}{54}{figure.caption.42}%
\contentsline {figure}{\numberline {5.4}{\ignorespaces Cost-coverage curves using MC-Dropout on $S_{in}$, $S_{unknown}$, and $S_{combined}$\relax }}{55}{figure.caption.45}%
\contentsline {figure}{\numberline {5.5}{\ignorespaces Cost-coverage curves. From left to right: \(S_{in}\), \(S_{unknown}\) and \(S_{combined}\).\relax }}{56}{figure.caption.46}%
\contentsline {figure}{\numberline {5.6}{\ignorespaces Cost-coverage curves for SelectiveNet and EC-SelectiveNet. From left to right: $C_{1,0}=1$ (symmetric costs), $10$, and $50$ (highly asymmetric costs)\relax }}{56}{figure.caption.48}%
\contentsline {figure}{\numberline {5.7}{\ignorespaces Cost-coverage curves for cross-entropy training and EC-SelectiveNet combined with temperature scaling. From left to right: $C_{1,0}=1$ (symmetric costs), $10$, and $50$ (highly asymmetric costs)\relax }}{57}{figure.caption.49}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {6.1}{\ignorespaces Example images from the SD-260 dataset\nobreakspace {}\citep {yang2019self}.\relax }}{64}{figure.caption.50}%
\contentsline {figure}{\numberline {6.2}{\ignorespaces Balanced accuracy of models when tested on Tayside and Forth Valley datasets after various pre-training sequences. Bars are +/- one standard error computed from the variance over cross-validation folds.\relax }}{69}{figure.caption.54}%
\contentsline {figure}{\numberline {6.3}{\ignorespaces Balanced accuracy of the models demonstrating the performance of dataset cross-generalisation between the Tayside and Forth Valley datasets.\relax }}{70}{figure.caption.55}%
\contentsline {figure}{\numberline {6.4}{\ignorespaces ROC curves for CNNs and SWIN transformers pre-trained on SD-260 prior to training on either Tayside or Forth Valley data.\relax }}{72}{figure.caption.56}%
\addvspace {10\p@ }
\addvspace {10\p@ }
